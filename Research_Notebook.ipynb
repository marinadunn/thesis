{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f911effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system level\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# machine learning\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, brier_score_loss\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Graphics in retina format are more sharp and legible\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25849359",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f0a073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load year 1 train, test, validation image files\n",
    "X_train_1 = np.load('images_Y1_train.npy')\n",
    "X_test_1 = np.load('images_Y1_test.npy')\n",
    "X_valid_1 = np.load('images_Y1_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47fe8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load year 10 train, test, validation image files\n",
    "X_train_10 = np.load('images_Y10_train.npy')\n",
    "X_test_10 = np.load('images_Y10_test.npy')\n",
    "X_valid_10 = np.load('images_Y10_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa5188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load year 1 and 10, label small subset test files\n",
    "X_test_1_small = np.load('images_Y1_test_150.npy')\n",
    "X_test_10_small = np.load('images_Y10_test_150.npy')\n",
    "Y_test_small = np.load('labels_test_150.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "121691e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image label files\n",
    "Y_train = np.load('labels_train.npy')\n",
    "Y_test = np.load('labels_test.npy')\n",
    "Y_valid = np.load('labels_valid.npy')\n",
    "\n",
    "Y_train_oh = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test_oh = tf.keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f6e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_df = pd.DataFrame(Y_train)\n",
    "Y_test_df = pd.DataFrame(Y_test)\n",
    "Y_valid_df = pd.DataFrame(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa4304fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables\n",
    "# 70:10:20 for training:valid:test\n",
    "NUM_TRAIN = 23487 # num train images\n",
    "NUM_TEST = 6715 # num test images\n",
    "NUM_VALIDATION = 3355 # num validation images\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd18931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33557\n"
     ]
    }
   ],
   "source": [
    "# check data sizes\n",
    "NUM_TOTAL = NUM_TRAIN + NUM_TEST + NUM_VALIDATION\n",
    "print(NUM_TOTAL)\n",
    "assert NUM_TOTAL == len(X_train_1) + len(X_test_1) + len(X_valid_1), \"total training, test, validation samples not equal to total samples - exiting\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e6c93",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec68bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_df.info()\n",
    "#Y_test_df.info()\n",
    "#Y_valid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3285360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_df.value_counts()\n",
    "#Y_test_df.value_counts()\n",
    "#Y_valid_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "999e1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_df.describe()\n",
    "#Y_test_df.describe()\n",
    "#Y_valid_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0a9c5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: \n",
      "Training Set (year 1):  (23487, 3, 100, 100) (23487, 3)\n",
      "Test Set (year 1):  (6715, 3, 100, 100) (6715, 3)\n",
      "Validation Set (year 1):  (3355, 3, 100, 100) (3355, 3)\n"
     ]
    }
   ],
   "source": [
    "print( \"Data dimensions: \") \n",
    "print( \"Training Set (year 1): \", np.shape(X_train_1), np.shape(Y_train)) # same for year 10\n",
    "print( \"Test Set (year 1): \", np.shape(X_test_1), np.shape(Y_test)) # same for year 10\n",
    "print( \"Validation Set (year 1): \", np.shape(X_valid_1), np.shape(Y_valid)) # same for year 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e787f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Y_train_df.set_axis(['Spiral', 'Elliptical', 'Merger'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec38716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.FacetGrid(data, col=\"Spiral\", hue=\"Spiral\")\n",
    "# g.map(sns.countplot, \"Spiral\");\n",
    "# g.add_legend(labels=[\"No\", \"Yes\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae892915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.FacetGrid(data, col=\"Elliptical\", hue=\"Elliptical\")\n",
    "# g.map(sns.countplot, \"Elliptical\");\n",
    "# g.add_legend(labels=[\"No\", \"Yes\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4756bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.FacetGrid(data, col=\"Merger\", hue=\"Merger\")\n",
    "# g.map(sns.countplot, \"Merger\");\n",
    "# g.add_legend(labels=[\"No\", \"Yes\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3fc583",
   "metadata": {},
   "source": [
    "```\n",
    "3 columns: spiral (or '0'), elliptical ('1'), or a galaxy merger ('2â€™)\n",
    "No null values, min:0, max:1\n",
    "\n",
    "Training Set: \n",
    "23487 images,\n",
    "dtype: int64,\n",
    "shape: (23487, 3, 100, 100)\n",
    "\n",
    "Training labels:\n",
    "\n",
    "spiral: \n",
    "\t10017 total,\n",
    "\tmean: 0.426491,\n",
    "\tstd: 0.494577\n",
    "\n",
    "elliptical: \n",
    "\t5705 total,\n",
    "\tmean: 0.242900,\n",
    "\tstd: 0.428844\n",
    "\n",
    "merger:\n",
    "\t7765 total\n",
    "\tmean: 0.330608\n",
    "\tstd: 0.470442\n",
    "\n",
    "Test Set: \n",
    "6715 images,\n",
    "dtype: int64,\n",
    "shape: (6715, 3, 100, 100)\n",
    "\n",
    "Test labels:\n",
    "spiral: \n",
    "\t2863 total,\n",
    "\tmean: 0.426359,\n",
    "\tstd: 0.494584\n",
    "\n",
    "elliptical:\n",
    "\t1631 total,\n",
    "\tmean: 0.242889,\n",
    "\tstd: 0.428861\n",
    "\n",
    "merger:\n",
    "\t2221 total,\n",
    "\tmean: 0.330752,\n",
    "\tstd: 0.470519\n",
    "\n",
    "Validation Set: \n",
    "3355 images,\n",
    "dtype: int64,\n",
    "shape: (3355, 3, 100, 100)\n",
    "\n",
    "Validation labels:\n",
    "spiral: \n",
    "\t1432 total,\n",
    "\tmean: 0.426826,\n",
    "\tstd: 0.494690\n",
    "\n",
    "elliptical:\n",
    "\t815 total,\n",
    "\tmean: 0.242921,\n",
    "\tstd: 0.428912\n",
    "\n",
    "merger:\n",
    "\t1108 total,\n",
    "\tmean: 0.330253,\n",
    "\tstd: 0.470374\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a4bb8",
   "metadata": {},
   "source": [
    "### Build and train a CNN model:\n",
    "First train a standard deterministic CNN classifier model as a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "462147a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.8.0\n",
      "Tensorflow Probability Version:  0.16.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Tensorflow Probability Version: \", tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b19f85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # default initial learning rate\n",
    "nb_epoch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = np.shape(x_data)\n",
    "input_shape = (2, 75, 75)\n",
    "\n",
    "x = Input(shape=input_shape)\n",
    "c0 = Convolution2D(8, (5, 5), activation='relu', strides=(1, 1), padding='same', data_format='channels_first')(x)\n",
    "b0 = BatchNormalization()(c0)\n",
    "d0 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_first')(b0)\n",
    "e0 = Dropout(0.5)(d0)\n",
    "\n",
    "c1 = Convolution2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same', data_format='channels_first')(e0)\n",
    "b1 = BatchNormalization()(c1)\n",
    "d1 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_first')(b1)\n",
    "e1 = Dropout(0.5)(d1)\n",
    "\n",
    "c2 = Convolution2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same', data_format='channels_first')(e1)\n",
    "b2 = BatchNormalization()(c2)\n",
    "d2 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_first')(b2)\n",
    "e2 = Dropout(0.5)(d2)\n",
    "\n",
    "f = Flatten()(e2)\n",
    "z0 = Dense(64, activation='softmax', kernel_regularizer=l2(0.0001))(f)\n",
    "z1 = Dense(32, activation='softmax', kernel_regularizer=l2(0.0001))(z0)\n",
    "y = Dense(1, activation='sigmoid')(z1)\n",
    "\n",
    "model = Model(inputs=x, outputs=y)\n",
    "\n",
    "# Compile Model\n",
    "optimizer = 'adam'\n",
    "metrics = ['accuracy']\n",
    "loss = 'binary_crossentropy'\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7585163e",
   "metadata": {},
   "source": [
    "### BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "78260c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0045a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "    \n",
    "#     tfp.layers.Convolution2DFlipout(\n",
    "#         6, kernel_size=5, padding='SAME', \n",
    "#         kernel_divergence_fn=kl_divergence_function, \n",
    "#         activation=tf.nn.relu),\n",
    "    \n",
    "#     tf.keras.layers.MaxPooling2D(\n",
    "#         pool_size=[2, 2], strides=[2, 2],\n",
    "#         padding='SAME'),\n",
    "\n",
    "#     tfp.layers.Convolution2DFlipout(\n",
    "#         16, kernel_size=5, padding='SAME', \n",
    "#         kernel_divergence_fn=kl_divergence_function, \n",
    "#         activation=tf.nn.relu),\n",
    "    \n",
    "#     tf.keras.layers.MaxPooling2D(\n",
    "#         pool_size=[2, 2], strides=[2, 2],\n",
    "#         padding='SAME'),\n",
    "    \n",
    "#     tfp.layers.Convolution2DFlipout(\n",
    "#         120, kernel_size=5, padding='SAME', \n",
    "#         kernel_divergence_fn=kl_divergence_function, \n",
    "#         activation=tf.nn.relu),\n",
    "    \n",
    "#     tf.keras.layers.Flatten(),\n",
    "    \n",
    "#     tfp.layers.DenseFlipout(\n",
    "#         84, kernel_divergence_fn=kl_divergence_function,\n",
    "#         activation=tf.nn.relu),\n",
    "    \n",
    "#     tfp.layers.DenseFlipout(\n",
    "#         NUM_CLASSES, kernel_divergence_fn=kl_divergence_function, \n",
    "#         activation=tf.nn.softmax)\n",
    "# ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a68026e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model inputs\n",
    "# FEATURE_NAMES = [\n",
    "#     \"Spiral\",\n",
    "#     \"Elliptical\",\n",
    "#     \"Merger\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# def create_model_inputs():\n",
    "#     inputs = {}\n",
    "#     for feature_name in FEATURE_NAMES:\n",
    "#         inputs[feature_name] = layers.Input(\n",
    "#             name=feature_name, shape=(1,), dtype=tf.int64\n",
    "#         )\n",
    "#     return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6ab51d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_experiment(model, loss, train_dataset, test_dataset):\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "#         loss=loss,\n",
    "#         metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "#     )\n",
    "\n",
    "#     print(\"Start training the model...\")\n",
    "#     model.fit(train_dataset, epochs=num_epochs, validation_data=test_dataset)\n",
    "#     print(\"Model training finished.\")\n",
    "#     _, rmse = model.evaluate(train_dataset, verbose=0)\n",
    "#     print(f\"Train RMSE: {round(rmse, 3)}\")\n",
    "\n",
    "#     print(\"Evaluating model performance...\")\n",
    "#     _, rmse = model.evaluate(test_dataset, verbose=0)\n",
    "#     print(f\"Test RMSE: {round(rmse, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd7344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research_env)",
   "language": "python",
   "name": "research_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
