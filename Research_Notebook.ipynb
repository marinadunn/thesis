{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6fe0f99",
   "metadata": {},
   "source": [
    "Created by Marina Dunn, Spring 2022\n",
    "\n",
    "**Resources used:**\n",
    "\n",
    "https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\n",
    "\n",
    "https://github.com/deepskies/deepmerge-public/blob/master/DeepMerge-noisy.ipynb\n",
    "\n",
    "https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939\n",
    "\n",
    "https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e\n",
    "\n",
    "https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-softmax-crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system level\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "from __future__ import print_function\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# machine learning\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.applications import VGG16\n",
    "#from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, brier_score_loss\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.patches as mpatches\n",
    "# Graphics in retina format are more sharp and legible\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5215f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25849359",
   "metadata": {},
   "source": [
    "### Load and define data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f0a073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load year 1 train, test, validation image files\n",
    "X_train_1 = np.load('images_Y1_train.npy')\n",
    "X_test_1 = np.load('images_Y1_test.npy')\n",
    "X_valid_1 = np.load('images_Y1_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fe8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load year 10 train, test, validation image files\n",
    "X_train_10 = np.load('images_Y10_train.npy')\n",
    "X_test_10 = np.load('images_Y10_test.npy')\n",
    "X_valid_10 = np.load('images_Y10_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa5188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load year 1 and 10, label small subset test files\n",
    "X_test_1_sub = np.load('images_Y1_test_150.npy')\n",
    "X_test_10_sub = np.load('images_Y10_test_150.npy')\n",
    "Y_test_sub = np.load('labels_test_150.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121691e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image label files\n",
    "Y_train_label = np.load('labels_train.npy')\n",
    "Y_test_label = np.load('labels_test.npy')\n",
    "Y_valid_label = np.load('labels_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91a582bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33557, 3, 100, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define full datasets by combining train + test + validation sets\n",
    "X_1_data = np.concatenate([X_train_1, X_test_1, X_valid_1], axis=0)\n",
    "np.shape(X_1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f08ff327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33557, 3, 100, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_10_data = np.concatenate([X_train_10, X_test_10, X_valid_10], axis=0)\n",
    "np.shape(X_10_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc843d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33557, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data = np.concatenate([Y_train_label, Y_test_label, Y_valid_label], axis=0)\n",
    "np.shape(Y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd31d1c",
   "metadata": {},
   "source": [
    "**Choosing batch size, epoch:**\n",
    "\n",
    "batch size: larger batch sizes result in faster progress in training, but don't always converge as fast. Smaller batch sizes train slower, but can converge faster. \n",
    "epoch: models improve with more epochs of training, to a point; will start to plateau in accuracy as they converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa4304fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables\n",
    "# 70:10:20 for training:valid:test\n",
    "NUM_TRAIN = 23487 # num train images\n",
    "NUM_TEST = 6715 # num test images\n",
    "NUM_VALIDATION = 3355 # num validation images\n",
    "shuffle = True\n",
    "NUM_EPOCH = 500\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c24bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "random.seed(5)\n",
    "idx = np.random.choice(len(X_1_data), size=len(X_1_data), replace=False)\n",
    "X_1_data = X_1_data[idx]\n",
    "X_10_data = X_10_data[idx]\n",
    "Y_data = Y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3dd9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice the image arrays\n",
    "\n",
    "ind_valid_start = ind_train_end = NUM_TRAIN\n",
    "ind_valid_end = ind_test_start = NUM_TRAIN + NUM_VALIDATION\n",
    "ind_test_end = NUM_TRAIN + NUM_VALIDATION + NUM_TEST\n",
    "\n",
    "X_train_1 = X_1_data[:ind_train_end, :, :, :]\n",
    "X_valid_1 = X_1_data[ind_valid_start: ind_valid_end, :, :, :]\n",
    "X_test_1 = X_1_data[ind_test_start: ind_test_end, :, :, :]\n",
    "\n",
    "X_train_10 = X_10_data[:ind_train_end, :, :, :]\n",
    "X_valid_10 = X_10_data[ind_valid_start: ind_valid_end, :, :, :]\n",
    "X_test_10 = X_10_data[ind_test_start: ind_test_end, :, :, :]\n",
    "\n",
    "# slice the label arrays\n",
    "Y_train = Y_data[:ind_train_end]\n",
    "Y_valid = Y_data[ind_valid_start: ind_valid_end]\n",
    "Y_test = Y_data[ind_test_start: ind_test_end]\n",
    "\n",
    "Y_data = Y_data[:, 0]\n",
    "Y_train = Y_train[:, 0]\n",
    "Y_valid = Y_valid[:, 0]\n",
    "Y_test = Y_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd18931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33557\n"
     ]
    }
   ],
   "source": [
    "# check data sizes\n",
    "NUM_TOTAL = NUM_TRAIN + NUM_TEST + NUM_VALIDATION\n",
    "print(NUM_TOTAL)\n",
    "assert NUM_TOTAL == len(X_train_1) + len(X_test_1) + len(X_valid_1), \"total training, test, validation samples not equal to total samples - exiting\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e6c93",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f6e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_df = pd.DataFrame(Y_train_label)\n",
    "# Y_test_df = pd.DataFrame(Y_test_label)\n",
    "# Y_valid_df = pd.DataFrame(Y_valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec68bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_df.info()\n",
    "#Y_test_df.info()\n",
    "#Y_valid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3285360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_df.value_counts()\n",
    "#Y_test_df.value_counts()\n",
    "#Y_valid_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "999e1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_df.describe()\n",
    "#Y_test_df.describe()\n",
    "#Y_valid_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060f73e6",
   "metadata": {},
   "source": [
    "Each image represents a series of pixels in a grid-like format with a value of brightness for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e41c825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: \n",
      "Input data:  (33557, 3, 100, 100) (33557,)\n",
      "Training Set:  (23487, 3, 100, 100) (23487,)\n",
      "Test Set:  (6715, 3, 100, 100) (6715,)\n",
      "Validation Set:  (3355, 3, 100, 100) (3355,)\n"
     ]
    }
   ],
   "source": [
    "print( \"Data dimensions: \")\n",
    "# training on year 1\n",
    "print( \"Input data: \", np.shape(X_1_data), np.shape(Y_data)) # same for year 10\n",
    "print( \"Training Set: \", np.shape(X_train_1), np.shape(Y_train)) # same for year 10\n",
    "print( \"Test Set: \", np.shape(X_test_1), np.shape(Y_test)) # same for year 10\n",
    "print( \"Validation Set: \", np.shape(X_valid_1), np.shape(Y_valid)) # same for year 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "264f40ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset Test Set:  (150, 3, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Subset Test Set: \", np.shape(X_test_1_sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3fc583",
   "metadata": {},
   "source": [
    "```\n",
    "Multi-Class Classification\n",
    "3 columns: spiral (or '0'), elliptical ('1'), or a galaxy merger ('2’) - (num_classes – 1)\n",
    "No null values, min:0, max:1\n",
    "dtype: int64\n",
    "\n",
    "(year 1)\n",
    "Training set details:\n",
    "• 23487 total images\n",
    "• 10017 Spiral galaxies (mean: 0.426491, std: 0.494577)\n",
    "• 5705 Elliptical galaxies (mean: 0.242900, std: 0.428844)\n",
    "• 7765 Merger galaxies (mean: 0.330608, std: 0.470442)\n",
    "• Memory usage: 550.6 KB\n",
    "\n",
    "Test set details:\n",
    "• 6715 total images\n",
    "• 2863 Spiral galaxies (mean: 0.426359, std: 0.494584)\n",
    "• 1631 Elliptical galaxies (mean: 0.242889, std: 0.428861)\n",
    "• 2221 Merger galaxies (mean: 0.330752, std: 0.470519)\n",
    "• Memory usage: 157.5 KB\n",
    "\n",
    "Validation set details:\n",
    "• 3355 total images\n",
    "• 1432 Spiral galaxies (mean: 0.426826, std: 0.494690)\n",
    "• 815 Elliptical galaxies (mean: 0.242921, std: 0.428912)\n",
    "• 1108 Merger galaxies (mean: 0.330253, std: 0.470374)\n",
    "• Memory usage: 78.8 KB\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11cc5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast data types as floats\n",
    "X_train_1 = X_train_1.astype('float32')\n",
    "X_test_1 = X_test_1.astype('float32')\n",
    "X_valid_1 = X_valid_1.astype('float32')\n",
    "\n",
    "X_train_10 = X_train_10.astype('float32')\n",
    "X_test_10 = X_test_10.astype('float32')\n",
    "X_valid_10 = X_valid_10.astype('float32')\n",
    "\n",
    "X_test_1_sub = X_test_1_sub.astype('float32')\n",
    "X_test_10_sub = X_test_10_sub.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dedec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize images\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a4bb8",
   "metadata": {},
   "source": [
    "### Build CNN model:\n",
    "First build a standard deterministic CNN classifier model as a baseline model. CNN/ConvNet typically uses ~3 convolution layers: a convolutional layer, a pooling layer, and a fully connected layer. The layer setup is such that simpler patterns are recognized first, then increasingly complex patterns thereafter.\n",
    "\n",
    "Perform series of convolution + pooling operations, then a number of fully connected layers. \n",
    "\n",
    "**Convolutional Layer:** Contains most of the network's main computational load. Performs dot product between kernel (matrix 1) and restricted portion of the receptive field (matrix 2). Forward pass. Creates an activation/feature map, or 2D representation of the image.\n",
    "\n",
    "**Pooling Layer:** provides summary statistic of nearby outputs at various network output locations. Pooling operation performed individually on every slice of activation map. Max pooling is most popular.\n",
    "\n",
    "**Fully Connected Layer:** helps map the representation b/w input and the output. Matrix multiplication, followed by a bias effect. Helps to learn non-linear combinations of features.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1) Train\n",
    "\n",
    "2) Validate on a holdout set generated from the original training data\n",
    "\n",
    "3) Evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "462147a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.8.0\n",
      "Tensorflow Probability Version:  0.16.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Tensorflow Probability Version: \", tfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dbddad",
   "metadata": {},
   "source": [
    "#### Defining CNN model architecture:\n",
    "\n",
    "##### Activation functions:\n",
    "\n",
    "**-Sigmoid:** σ(κ) = 1/(1+e¯κ), takes real-value number & “squashes” into a range 0-1\n",
    "\n",
    "**-ReLU/'relu':** Rectified Linear Unit, calculates ƒ(κ)=max (0,κ), or the activation is simply threshold at 0. More reliable + faster than sigmoid, tanh. More non-linearity gives more power to the model\n",
    "\n",
    "**-Softmax/Normalized Exponential:** converts a vector of numbers into a vector of probabilities, where the probabilities of each value are proportional to the relative scale of each value in the vector.\n",
    "\n",
    "##### Keras layers:\n",
    "\n",
    "**Convolution2D():** 2D convolution layer (e.g. spatial convolution over images). \n",
    "\n",
    "-args: activation (activation function to use), \n",
    "\n",
    "**MaxPooling2D():** Max pooling operation for 2D spatial data\n",
    "\n",
    "-args: pool_size (window size over which to take the maximum), strides (Specifies how far the pooling window moves for each pooling step; sliding size of the kernel), padding (''valid\"- no padding, or ''same\"- padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input), data_format (ordering of the dimensions in the inputs)\n",
    "\n",
    "data_format='channels_first': \n",
    "\n",
    "input: 4D tensor with shape (batch_size, channels, rows, cols)\n",
    "output: 4D tensor with shape (batch_size, channels, pooled_rows, pooled_cols).\n",
    "\n",
    "**Dense():** regular densely-connected neural network layer (describes a layer of neurons)\n",
    "\n",
    "-args: activation (activation function to use), kernel_regularizer (regularizer function applied to the kernel weights matrix)\n",
    "\n",
    "##### Regularization\n",
    "**Dropout:** Most popular regularization technique, prevents overfitting. At each iteration, neuron temporarily “dropped” with probability 'p'. This neuron is resampled with 'p' at every training step, so will be active at next step. Typically ~0.5 or 50%. Can be applied to input or hidden layer nodes, but not output nodes. \n",
    "\n",
    "**Batch Normalization:** explicitly forces the activations throughout a network to take on a Gaussian distribution at the beginning of training, applying a transformation that maintains mean output close to 0 and output standard deviation close to 1. BatchNorm layer inserted immediately after fully connected layers, or convolutional layers, and before non-linearities. Significantly more robust to bad initialization.\n",
    "\n",
    "##### Keras Early stopping\n",
    "**Early stopping:** Early stopping call back function can be used to monitor either accuracy or loss, stopping when there's either a loss increment, or accuracy decrement. Should monitor the thing that is more sensitive, which is usually loss function- will start seeing signs of overfitting in loss earlier. \n",
    "\n",
    "##### Keras Optimizers:  \n",
    "**Adam:** implements the Adam algorithm; learning rate of 0.001. Stochastic gradient descent method based on adaptive estimation of 1st-order and 2nd-order moments. Very performant.\n",
    "\n",
    "##### Loss function: \n",
    "**Categorical Cross-entropy:** Computes the cross-entropy loss between the labels and predictions. Used when adjusting model weights during training. Categorical cross-entropy is used with 'softmax' activation for multi-class classification problem, i.e. when true label values are one-hot encoded for 3-class classification problem.\n",
    "\n",
    "**Sparse Categorical Cross-entropy:** Same as above, but does not require one-hot encoding. Used when there are many labels.\n",
    "\n",
    "##### Additional techniques to potentially look at:\n",
    "**Cross validation:** (i.e. k-fold), partition the original training data set into k equal subsets, each called a fold (named f1, f2, …, fk, for i = 1 to i = k). Keep the fold fi as the Validation set, and keep all the remaining k-1 folds in the Cross validation training set. Train model using the cross validation training set; calculate accuracy by validating predicted results against the validation set. Estimate accuracy of model by averaging the accuracies derived in all the k cases of cross validation. Helps reduce overfitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09808d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spiral', 'Elliptical', 'Merger']\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Spiral', 'Elliptical', 'Merger']\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c31bc6",
   "metadata": {},
   "source": [
    "Image -> Conv layer -> Pool Layer -> Conv layer -> Pool Layer - > Conv layer -> Pool Layer - > Flatten -> Dense -> Dense-> Dense-> Dense-> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c8f9034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model layers, build with the Functional API\n",
    "data_shape = np.shape(X_1_data)\n",
    "#(channels, rows, cols)\n",
    "input_shape = (3, 100, 100)\n",
    "\n",
    "# Constraints for layer 1\n",
    "# input: tensors of shape (color_channels, image_height, image_width), ignoring batch size\n",
    "x = Input(shape=input_shape)\n",
    "#For CNN: Convolution typically uses 3x3 windows, stride 1 & with padding. Will try 5x5 window first to attempt tp catch more features, but try multiple\n",
    "c0 = Conv2D(8, (5, 5), activation='relu', strides=(1, 1), padding='same', data_format='channels_first', name='conv_1')(x)\n",
    "b0 = BatchNormalization()(c0)\n",
    "#For CNN: pooling typically uses 2x2 windows, stride 2 & no padding\n",
    "d0 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_first', name='maxpool_1')(b0)\n",
    "e0 = Dropout(0.5)(d0)\n",
    "\n",
    "# Constraints for layer 2\n",
    "c1 = Conv2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same', data_format='channels_first', name='conv_2')(e0)\n",
    "b1 = BatchNormalization()(c1)\n",
    "d1 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_first', name='maxpool_2')(b1)\n",
    "e1 = Dropout(0.5)(d1)\n",
    "\n",
    "# Constraints for layer 3\n",
    "c2 = Conv2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same', data_format='channels_first', name='conv_3')(e1)\n",
    "b2 = BatchNormalization()(c2)\n",
    "d2 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_first', name='maxpool_3')(b2)\n",
    "e2 = Dropout(0.5)(d2)\n",
    "\n",
    "\n",
    "# Constraints for layer 4\n",
    "#flatten (or unroll) the 3D output to 1D\n",
    "f = Flatten()(e2)\n",
    "# Dense layer: takes 1D vector as input, current output is a 3D tensor; start simple, then change unit to try to increase performance\n",
    "z0 = Dense(512, activation='relu', name='dense_1')(f)\n",
    "z1 = Dense(256, activation='relu', name='dense_2')(z0)\n",
    "# use L2 regulization: take sum of all params squared & add it w/ square difference of actual output & predictions\n",
    "# weights not sparse, will get much better accuracy than L1\n",
    "z2 = Dense(64, activation='relu', kernel_regularizer=l2(0.0001), name='dense_3')(z1)\n",
    "z3 = Dense(32, activation='relu', kernel_regularizer=l2(0.0001), name='dense_4')(z2)\n",
    "# output layer must create 3 output values, one for each class\n",
    "# use “softmax” activation function to ensure output values are in range 0-1 & may be used as predicted probabilities\n",
    "y = Dense(3, activation='softmax', name='output')(z3)\n",
    "\n",
    "model = Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89459ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3, 100, 100)]     0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 8, 100, 100)       608       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 100, 100)      400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " maxpool_1 (MaxPooling2D)    (None, 8, 50, 50)         0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 50, 50)         0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 16, 50, 50)        1168      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 50, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " maxpool_2 (MaxPooling2D)    (None, 16, 25, 25)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 25, 25)        0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 32, 25, 25)        4640      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 25, 25)       100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " maxpool_3 (MaxPooling2D)    (None, 32, 12, 12)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 12, 12)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               2359808   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,516,879\n",
      "Trainable params: 2,516,529\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile Model\n",
    "optimizer = 'adam'\n",
    "metrics = ['accuracy']\n",
    "# Multi-Class Cross-Entropy Loss\n",
    "loss = 'sparse_categorical_crossentropy' \n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics, include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c851560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "monitor: value to be monitored by the function: validation loss or validation accuracy\n",
    "mode: mode in which change in the quantity monitored should be observed: ‘min’, ‘max’, or ‘auto’. \n",
    "For loss, value is ‘min’. For accuracy, value is ‘max’. ‘auto’: monitors with auto suitable mode\n",
    "patience: number of epochs for the training to be continued after the first halt for any improvement in the model\n",
    "verbose: integer value- 0, 1 or 2, selects the way in which progress is displayed while training\n",
    "Verbose = 1: A bar depicting the progress of training is displayed\n",
    "\"\"\"\n",
    "\n",
    "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50),\n",
    "# Save best weights in order to maximize validation accuracy, only saves when the model is considered the \"best\"\n",
    "     ModelCheckpoint(filepath='/best_weights', monitor='val_acc', mode='max', verbose=1, save_best_only=True)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf3cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 20:07:03.034278: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - ETA: 0s - loss: 0.6520 - accuracy: 0.6635WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 83s 445ms/step - loss: 0.6520 - accuracy: 0.6635 - val_loss: 0.8134 - val_accuracy: 0.6238\n",
      "Epoch 2/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7195WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 81s 440ms/step - loss: 0.5660 - accuracy: 0.7195 - val_loss: 0.6066 - val_accuracy: 0.7043\n",
      "Epoch 3/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.7483WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 81s 439ms/step - loss: 0.5295 - accuracy: 0.7483 - val_loss: 0.5164 - val_accuracy: 0.7669\n",
      "Epoch 4/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.7578WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 448ms/step - loss: 0.5088 - accuracy: 0.7578 - val_loss: 0.6428 - val_accuracy: 0.6918\n",
      "Epoch 5/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.7688WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 445ms/step - loss: 0.4927 - accuracy: 0.7688 - val_loss: 0.6188 - val_accuracy: 0.6751\n",
      "Epoch 6/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.7780WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 0.4749 - accuracy: 0.7780 - val_loss: 0.5399 - val_accuracy: 0.7446\n",
      "Epoch 7/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.4538 - accuracy: 0.7899WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 444ms/step - loss: 0.4538 - accuracy: 0.7899 - val_loss: 0.6303 - val_accuracy: 0.6999\n",
      "Epoch 8/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.7998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 0.4404 - accuracy: 0.7998 - val_loss: 0.4924 - val_accuracy: 0.7642\n",
      "Epoch 9/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.8116WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 0.4215 - accuracy: 0.8116 - val_loss: 0.4736 - val_accuracy: 0.7717\n",
      "Epoch 10/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.4102 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 447ms/step - loss: 0.4102 - accuracy: 0.8151 - val_loss: 0.4397 - val_accuracy: 0.7905\n",
      "Epoch 11/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.8196WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 0.3994 - accuracy: 0.8196 - val_loss: 0.4882 - val_accuracy: 0.7672\n",
      "Epoch 12/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.3778 - accuracy: 0.8325WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 445ms/step - loss: 0.3778 - accuracy: 0.8325 - val_loss: 0.4347 - val_accuracy: 0.7967\n",
      "Epoch 13/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.8411WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 0.3605 - accuracy: 0.8411 - val_loss: 0.4261 - val_accuracy: 0.8116\n",
      "Epoch 14/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8516WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 0.3383 - accuracy: 0.8516 - val_loss: 0.4310 - val_accuracy: 0.8155\n",
      "Epoch 15/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.8584WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 0.3277 - accuracy: 0.8584 - val_loss: 0.4588 - val_accuracy: 0.8235\n",
      "Epoch 16/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.8681WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 447ms/step - loss: 0.3076 - accuracy: 0.8681 - val_loss: 0.4756 - val_accuracy: 0.8143\n",
      "Epoch 17/500\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.8793WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "184/184 [==============================] - 82s 445ms/step - loss: 0.2831 - accuracy: 0.8793 - val_loss: 0.4319 - val_accuracy: 0.8274\n",
      "Epoch 18/500\n",
      " 73/184 [==========>...................] - ETA: 49s - loss: 0.2454 - accuracy: 0.9018"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "\n",
    "history = model.fit(\n",
    "                    X_train_1, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=NUM_EPOCH,\n",
    "                    validation_data=(X_valid_1, Y_valid),                \n",
    "                    shuffle=shuffle,\n",
    "                    verbose=True,\n",
    "                    callbacks=es\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "\n",
    "score = model.evaluate(X_test_1, Y_test, verbose=True)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697352fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test smaller subset\n",
    "Y_test_sub = Y_test_sub[:, 0]\n",
    "score = model.evaluate(X_test_1_sub, Y_test_sub, verbose=True)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training results\n",
    "\n",
    "# Accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = list(range(len(loss)))\n",
    "\n",
    "#plot\n",
    "figsize=(6,4)\n",
    "fig, axis1 = plt.subplots(figsize=figsize)\n",
    "\n",
    "plot1_lacc = axis1.plot(epochs, acc, 'navy', label='accuracy')\n",
    "plot1_val_lacc = axis1.plot(epochs, val_acc, 'deepskyblue', label=\"Validation Accuracy\")\n",
    "\n",
    "plot1_loss = axis1.plot(epochs, loss, 'red', label='loss')\n",
    "plot1_val_loss = axis1.plot(epochs, val_loss, 'lightsalmon', label=\"Validation Loss\")\n",
    "\n",
    "\n",
    "plots = plot1_loss + plot1_val_loss\n",
    "labs = [l.get_label() for l in plots]\n",
    "\n",
    "axis1.set_xlabel('Epoch')\n",
    "axis1.set_ylabel('Loss/Accuracy')\n",
    "plt.title(\"Loss/Accuracy History (Year 1 Images)\")\n",
    "plt.tight_layout()\n",
    "axis1.legend(loc='center right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff2b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "prob = model.predict(X_test_1)\n",
    "pred = (prob > 0.5).astype('int32') \n",
    "\n",
    "# measure confusion\n",
    "labels=[0, 1]\n",
    "cm = metrics.confusion_matrix(Y_test, pred, labels=labels)\n",
    "cm = cm.astype('float')\n",
    "cm_norm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(\"cm\", cm)\n",
    "print(\"cm_norm\", cm_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, prob, pos_label=1)\n",
    "auc = metrics.roc_auc_score(Y_test, prob)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "#plotting\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "\n",
    "plt.title('Confusion matrix (Year 1 Images)', y=1.08)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "fmt = '.2f'\n",
    "thresh = cm_norm.max() / 2.\n",
    "\n",
    "for i in range(cm_norm.shape[0]):\n",
    "    for j in range(cm_norm.shape[1]):\n",
    "        ax.text(j, i, format(cm_norm[i, j], fmt),\n",
    "        ha=\"center\", va=\"center\",\n",
    "        color=\"white\" if cm_norm[i, j] < thresh else \"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e543f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, pred)\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y_test, pred)\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Y_test, pred)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# brier score\n",
    "bs = brier_score_loss(Y_test, prob)\n",
    "print('Brier score: %f' % bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8bae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC TEST SET\n",
    "figsize=(5,5)\n",
    "fig, axis1 = plt.subplots(figsize=figsize)\n",
    "\n",
    "x_onetoone = y_onetoone = [0, 1]\n",
    "\n",
    "plt.plot(fpr, tpr, 'r-')\n",
    "plt.plot(x_onetoone, y_onetoone, 'k--',  label=\"1-1\")\n",
    "plt.legend(loc=0)\n",
    "plt.title(\"Receiver Operator Characteristic (ROC)\")\n",
    "plt.xlabel(\"False Positive (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive (Selectivity)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6532be68",
   "metadata": {},
   "source": [
    "## Visualizing Feature/Activation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c01894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the outputs of all layers except the input layer\n",
    "layer_outputs = [layer.output for layer in model.layers[1:]] \n",
    "# Creates a model that will return these outputs, given the model input\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs) \n",
    "\n",
    "# returns the values of the layer activations in original model\n",
    "# Returns a list of Numpy arrays: one array per layer activation\n",
    "activations = activation_model.predict(X_test_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation maps for all 8 filters in the first convolutional layer\n",
    "fig1=plt.figure(figsize=(10,1.5))  \n",
    "for i in range(8):\n",
    "    plt.subplot(1, 8, i + 1)\n",
    "    layer_activation = activations[0]\n",
    "    plt.imshow(layer_activation[1649, i, :, :], cmap='viridis', aspect='auto')\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "# activation maps for all 16 filters in the second convolutional layer    \n",
    "fig2=plt.figure(figsize=(10,3))  \n",
    "for i in range(16):\n",
    "    plt.subplot(2, 8, i + 1)\n",
    "    layer_activation = activations[4]\n",
    "    plt.imshow(layer_activation[1649, i, :, :], cmap='viridis', aspect='auto')\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)\n",
    "    \n",
    "# activation maps for all 32 filters in the third convolutional layer\n",
    "fig3=plt.figure(figsize=(10,6))  \n",
    "for i in range(32):\n",
    "    plt.subplot(4, 8, i + 1)\n",
    "    layer_activation = activations[8]\n",
    "    plt.imshow(layer_activation[1649, i, :, :], cmap='viridis', aspect='auto')\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0648c2",
   "metadata": {},
   "source": [
    "## Dense Layer Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5542d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility to search for layer index by name. \n",
    "# Alternatively we can specify this as -1 since it corresponds to the last layer.\n",
    "layer_idx = utils.find_layer_idx(model, 'predictions')\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "model = utils.apply_modifications(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7493ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Images\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    if (Y_test[i] == 1 and pred[i,0] == 1): # and other Y_test vs pred combinations TP=(1,1), FP=(0,1), TN=(0,0), FN=(1,0)\n",
    "        print (i)\n",
    "        print(Y_test[i],pred[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ba988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print output probabilities for the chosen TP, FP, TN, FN examples\n",
    "\n",
    "print(prob[84],prob[1370],prob[2031],prob[3003]) # TP examples\n",
    "print(prob[560],prob[1228],prob[2878],prob[3026]) # FP examples\n",
    "print(prob[564],prob[1056],prob[2083],prob[3063]) # TN examples\n",
    "print(prob[465],prob[1546],prob[2241],prob[3037]) # FN examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot examples\n",
    "tp1 = X_test_1[84,1]\n",
    "tp2 = X_test_1[1370,1]\n",
    "tp3 = X_test_1[2031,1]\n",
    "tp4 = X_test_1[3003,1]\n",
    "\n",
    "fp1 = X_test_1[560,1]\n",
    "fp2 = X_test_1[1228,1]\n",
    "fp3 = X_test_1[2878,1]\n",
    "fp4 = X_test_1[3026,1]\n",
    "\n",
    "tn1 = X_test_1[564,1]\n",
    "tn2 = X_test_1[1056,1]\n",
    "tn3 = X_test_1[2083,1]\n",
    "tn4 = X_test_1[3063,1]\n",
    "\n",
    "fn1 = X_test_1[465,1]\n",
    "fn2 = X_test_1[1546,1]\n",
    "fn3 = X_test_1[2241,1]\n",
    "fn4 = X_test_1[3037,1]\n",
    "\n",
    "examples = [tp1, tp2, tp3, tp4, fp1, fp2, fp3, fp4, tn1, tn2, tn3, tn4, fn1, fn2, fn3, fn4]\n",
    "\n",
    "fig1=plt.figure(figsize=(8,8))\n",
    "\n",
    "for i, image in enumerate(examples):\n",
    "    fig1.suptitle('From top row to bottom: TP, FP, TN, FN', fontsize=20)\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image, aspect='auto', cmap='viridis')\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ba588",
   "metadata": {},
   "source": [
    "## Visualizing Convnet Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340dbd9",
   "metadata": {},
   "source": [
    "### Data Augmentation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18850785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data should not be augmented!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7585163e",
   "metadata": {},
   "source": [
    "### BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78260c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0045a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "    \n",
    "#     tfp.layers.Convolution2DFlipout(\n",
    "#         6, kernel_size=5, padding='SAME', \n",
    "#         kernel_divergence_fn=kl_divergence_function, \n",
    "#         activation=tf.nn.relu),\n",
    "    \n",
    "#     tf.keras.layers.MaxPooling2D(\n",
    "#         pool_size=[2, 2], strides=[2, 2],\n",
    "#         padding='SAME'),\n",
    "\n",
    "#     tfp.layers.Convolution2DFlipout(\n",
    "#         16, kernel_size=5, padding='SAME', \n",
    "#         kernel_divergence_fn=kl_divergence_function, \n",
    "#         activation=tf.nn.relu),\n",
    "    \n",
    "#     tf.keras.layers.MaxPooling2D(\n",
    "#         pool_size=[2, 2], strides=[2, 2],\n",
    "#         padding='SAME'),\n",
    "    \n",
    "#     tfp.layers.Convolution2DFlipout(\n",
    "#         120, kernel_size=5, padding='SAME', \n",
    "#         kernel_divergence_fn=kl_divergence_function, \n",
    "#         activation=tf.nn.relu),\n",
    "    \n",
    "#     tf.keras.layers.Flatten(),\n",
    "    \n",
    "#     tfp.layers.DenseFlipout(\n",
    "#         84, kernel_divergence_fn=kl_divergence_function,\n",
    "#         activation=tf.nn.relu),\n",
    "    \n",
    "#     tfp.layers.DenseFlipout(\n",
    "#         NUM_CLASSES, kernel_divergence_fn=kl_divergence_function, \n",
    "#         activation=tf.nn.softmax)\n",
    "# ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68026e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model inputs\n",
    "# FEATURE_NAMES = [\n",
    "#     \"Spiral\",\n",
    "#     \"Elliptical\",\n",
    "#     \"Merger\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# def create_model_inputs():\n",
    "#     inputs = {}\n",
    "#     for feature_name in FEATURE_NAMES:\n",
    "#         inputs[feature_name] = layers.Input(\n",
    "#             name=feature_name, shape=(1,), dtype=tf.int64\n",
    "#         )\n",
    "#     return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab51d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_experiment(model, loss, train_dataset, test_dataset):\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "#         loss=loss,\n",
    "#         metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "#     )\n",
    "\n",
    "#     print(\"Start training the model...\")\n",
    "#     model.fit(train_dataset, epochs=num_epochs, validation_data=test_dataset)\n",
    "#     print(\"Model training finished.\")\n",
    "#     _, rmse = model.evaluate(train_dataset, verbose=0)\n",
    "#     print(f\"Train RMSE: {round(rmse, 3)}\")\n",
    "\n",
    "#     print(\"Evaluating model performance...\")\n",
    "#     _, rmse = model.evaluate(test_dataset, verbose=0)\n",
    "#     print(f\"Test RMSE: {round(rmse, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd7344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research_env)",
   "language": "python",
   "name": "research_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
