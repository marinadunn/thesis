{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6fe0f99",
   "metadata": {},
   "source": [
    "Created by Marina Dunn, Spring 2022\n",
    "\n",
    "**Resources used:**\n",
    "\n",
    "https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\n",
    "\n",
    "https://github.com/deepskies/deepmerge-public/blob/master/DeepMerge-noisy.ipynb\n",
    "\n",
    "https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939\n",
    "\n",
    "https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e\n",
    "\n",
    "https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-softmax-crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f911effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system level\n",
    "import os\n",
    "import codecs\n",
    "import sys\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy import interp\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import __future__\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# machine learning\n",
    "import tensorflow as tf\n",
    "#import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Sequential, Model, model_from_json, load_model\n",
    "from tensorflow.keras.layers import BatchNormalization, Input, Flatten, Dense\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Activation, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, BackupAndRestore, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import models\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, brier_score_loss\n",
    "\n",
    "# hyperparameter optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# plotting\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.patches as mpatches\n",
    "# Graphics in retina format are more sharp and legible\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25849359",
   "metadata": {},
   "source": [
    "### Load and define data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0a073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load year 1 train, test, validation image files\n",
    "X_train_1 = np.load('images_Y1_train.npy')\n",
    "X_test_1 = np.load('images_Y1_test.npy')\n",
    "X_valid_1 = np.load('images_Y1_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa5188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load year 1, label small subset test files\n",
    "X_test_1_sub = np.load('images_Y1_test_150.npy')\n",
    "Y_test_sub = np.load('labels_test_150.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121691e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image label files\n",
    "Y_train = np.load('labels_train.npy')\n",
    "Y_test = np.load('labels_test.npy')\n",
    "Y_valid = np.load('labels_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa95586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial training variables for model 1\n",
    "# 70:10:20 for training:valid:test\n",
    "NUM_TRAIN = 23487 # num train images\n",
    "NUM_TEST = 6715 # num test images\n",
    "NUM_VALIDATION = 3355 # num validation images\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf53ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "random.seed(5)\n",
    "idx = np.random.choice(len(X_train_1), size=len(X_train_1), replace=False)\n",
    "X_train_1 = X_train_1[idx]\n",
    "idx = np.random.choice(len(X_test_1), size=len(X_test_1), replace=False)\n",
    "X_test_1 = X_test_1[idx]\n",
    "idx = np.random.choice(len(X_valid_1), size=len(X_valid_1), replace=False)\n",
    "X_valid_1 = X_valid_1[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00ac5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(Y_train), size=len(Y_train), replace=False)\n",
    "Y_train = Y_train[idx]\n",
    "idx = np.random.choice(len(Y_test), size=len(Y_test), replace=False)\n",
    "Y_test = Y_test[idx]\n",
    "idx = np.random.choice(len(Y_valid), size=len(Y_valid), replace=False)\n",
    "Y_valid = Y_valid[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11cc5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast data types as floats\n",
    "X_train_1 = X_train_1.astype('float32')\n",
    "X_test_1 = X_test_1.astype('float32')\n",
    "X_valid_1 = X_valid_1.astype('float32')\n",
    "X_test_1_sub = X_test_1_sub.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd18931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33557\n"
     ]
    }
   ],
   "source": [
    "# check data sizes\n",
    "NUM_TOTAL = NUM_TRAIN + NUM_TEST + NUM_VALIDATION\n",
    "print(NUM_TOTAL)\n",
    "assert NUM_TOTAL == len(X_train_1) + len(X_test_1) + len(X_valid_1), \"total training, test, validation samples not equal to total samples - exiting\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "462147a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow Version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e6c93",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f6e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_df = pd.DataFrame(Y_train)\n",
    "# Y_test_df = pd.DataFrame(Y_test)\n",
    "# Y_valid_df = pd.DataFrame(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec68bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_df.info()\n",
    "#Y_test_df.info()\n",
    "#Y_valid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3285360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_df.value_counts()\n",
    "#Y_test_df.value_counts()\n",
    "#Y_valid_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "999e1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_df.describe()\n",
    "#Y_test_df.describe()\n",
    "#Y_valid_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e41c825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: \n",
      "Training Set:  (23487, 3, 100, 100) (23487, 3)\n",
      "Test Set:  (6715, 3, 100, 100) (6715, 3)\n",
      "Validation Set:  (3355, 3, 100, 100) (3355, 3)\n"
     ]
    }
   ],
   "source": [
    "print( \"Data dimensions: \")\n",
    "# training on year 1\n",
    "print( \"Training Set: \", np.shape(X_train_1), np.shape(Y_train)) # same for year 10\n",
    "print( \"Test Set: \", np.shape(X_test_1), np.shape(Y_test)) # same for year 10\n",
    "print( \"Validation Set: \", np.shape(X_valid_1), np.shape(Y_valid)) # same for year 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "264f40ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset Test Set:  (150, 3, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Subset Test Set: \", np.shape(X_test_1_sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060f73e6",
   "metadata": {},
   "source": [
    "Each image represents a series of pixels in a grid-like format with a value of brightness for each pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3fc583",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "Multi-Class Classification\n",
    "3 columns: spiral (or '0'), elliptical ('1'), or a galaxy merger ('2’) - (num_classes – 1)\n",
    "No null values, min:0, max:1\n",
    "\n",
    "(year 1)\n",
    "Training set details:\n",
    "• 23487 total images\n",
    "• 10017 Spiral galaxies (mean: 0.426491, std: 0.494577)\n",
    "• 5705 Elliptical galaxies (mean: 0.242900, std: 0.428844)\n",
    "• 7765 Merger galaxies (mean: 0.330608, std: 0.470442)\n",
    "• Memory usage: 550.6 KB\n",
    "\n",
    "Test set details:\n",
    "• 6715 total images\n",
    "• 2863 Spiral galaxies (mean: 0.426359, std: 0.494584)\n",
    "• 1631 Elliptical galaxies (mean: 0.242889, std: 0.428861)\n",
    "• 2221 Merger galaxies (mean: 0.330752, std: 0.470519)\n",
    "• Memory usage: 157.5 KB\n",
    "\n",
    "Validation set details:\n",
    "• 3355 total images\n",
    "• 1432 Spiral galaxies (mean: 0.426826, std: 0.494690)\n",
    "• 815 Elliptical galaxies (mean: 0.242921, std: 0.428912)\n",
    "• 1108 Merger galaxies (mean: 0.330253, std: 0.470374)\n",
    "• Memory usage: 78.8 KB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a4bb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deterministic CNN model:\n",
    "First build a standard deterministic CNN classifier model as a baseline model. CNN/ConvNet typically uses convolutional layers, pooling layers, and fully-connected layers. The layer setup is such that simpler patterns are recognized first, then increasingly complex patterns thereafter. Perform series of convolution + pooling operations, then a number of fully connected layers. \n",
    "\n",
    "**Convolutional Layer:** Contains most of the network's main computational load. Performs dot product between kernel (matrix 1) and restricted portion of the receptive field (matrix 2). Forward pass. Creates an activation/feature map, or 2D representation of the image.\n",
    "\n",
    "**Pooling Layer:** provides summary statistic of nearby outputs at various network output locations. Pooling operation performed individually on every slice of activation map. Max pooling is most popular.\n",
    "\n",
    "**Fully Connected Layer:** helps map the representation b/w input and the output. Matrix multiplication, followed by a bias effect. Helps to learn non-linear combinations of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dbddad",
   "metadata": {},
   "source": [
    "### Defining CNN model architecture:\n",
    "\n",
    "#### Activation functions used:\n",
    "\n",
    "**-ReLU/'relu':** Rectified Linear Unit, calculates ƒ(κ)=max (0,κ), or the activation is simply threshold at 0. More reliable + faster than sigmoid, tanh. More non-linearity gives more power to the model\n",
    "\n",
    "**-Softmax/Normalized Exponential:** converts a vector of numbers into a vector of probabilities, where the probabilities of each value are proportional to the relative scale of each value in the vector. Because labels are one-hot encoded, this will be used for final fully connected layer for 3 classes.\n",
    "\n",
    "#### Keras layers used:\n",
    "\n",
    "**Convolution2D():** 2D convolution layer (e.g. spatial convolution over images). \n",
    "\n",
    "-args: activation (activation function to use); used with Rectified Linear Unit activation function for these models.\n",
    "\n",
    "**MaxPooling2D():** Max pooling operation for 2D spatial data\n",
    "\n",
    "-args: pool_size (window size over which to take the maximum), strides (Specifies how far the pooling window moves for each pooling step; sliding size of the kernel), padding (''valid\"- no padding, or ''same\"- padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input), data_format (ordering of the dimensions in the inputs)\n",
    "\n",
    "used data_format='channels_first'\n",
    "\n",
    "**Dense():** regular densely-connected neural network layer (describes a layer of neurons)\n",
    "\n",
    "-args: activation (activation function to use), kernel_regularizer (regularizer function applied to the kernel weights matrix)\n",
    "\n",
    "#### Regularization Techniques Used:\n",
    "**Dropout:** Most popular regularization technique, prevents overfitting. At each iteration, neuron temporarily “dropped” with probability 'p'. This neuron is resampled with 'p' at every training step, so will be active at next step. Typically ~0.5 or 50%. Can be applied to input or hidden layer nodes, but not output nodes. Attempted to use rates of 0.5 and 0.8, as not enough computing power to use GridSearchCV to determine best rate.\n",
    "\n",
    "**Batch Normalization:** Explicitly forces the activations throughout a network to take on a Gaussian distribution at the beginning of training, applying a transformation that maintains mean output close to 0 and output standard deviation close to 1. BatchNorm layer inserted immediately after fully connected layers, or convolutional layers, and before non-linearities. Significantly more robust to bad initialization.\n",
    "\n",
    "**L2 Regularization**\n",
    "\n",
    "#### Keras Callbacks used:\n",
    "**Early stopping:** Early stopping call back function can be used to monitor either accuracy or loss, stopping when there's either a loss increment, or accuracy decrement. Should monitor the thing that is more sensitive, which is usually loss function- will start seeing signs of overfitting in loss earlier. \n",
    "\n",
    "**Model Checkpoint:** Save only best weights in order to maximize, in this case, validation accuracy (only saves when the model is considered the \"best\").\n",
    "\n",
    "**ReduceLROnPlateau:** Attempt to adjust learning rate, in this case by 0.1, if validation loss begins to plateau. Did not implement until Model 2.\n",
    "\n",
    "**BackupAndRestore:** Save backup of model in case training is interrupted.\n",
    "\n",
    "#### Keras Optimizers used:  \n",
    "**Adam:** implements the Adam algorithm; learning rate of 0.001. Stochastic gradient descent method based on adaptive estimation of 1st-order and 2nd-order moments, very performant and recommended by similar papers for this type of project.\n",
    "\n",
    "#### Loss function used: \n",
    "**Categorical Cross-entropy:** Computes the cross-entropy loss between the labels and predictions. Used when adjusting model weights during training. Categorical cross-entropy is used with 'softmax' activation for multi-class classification problem, i.e. when true label values are one-hot encoded for 3-class classification problem, as is the case with this project.\n",
    "\n",
    "#### Additional techniques to potentially look at:\n",
    "**Cross validation:** (i.e. k-fold), partition the original training data set into k equal subsets, each called a fold (named f1, f2, …, fk, for i = 1 to i = k). Keep the fold fi as the Validation set, and keep all the remaining k-1 folds in the Cross validation training set. Train model using the cross validation training set; calculate accuracy by validating predicted results against the validation set. Estimate accuracy of model by averaging the accuracies derived in all the k cases of cross validation. Helps reduce overfitting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd31d1c",
   "metadata": {},
   "source": [
    "**Choosing batch size, epoch:**\n",
    "\n",
    "batch size: larger batch sizes result in faster progress in training, but don't always converge as fast. Smaller batch sizes train slower, but can converge faster. \n",
    "epoch: models improve with more epochs of training, to a point; will start to plateau in accuracy as they converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09808d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spiral', 'Elliptical', 'Merger']\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Spiral', 'Elliptical', 'Merger']\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a94405",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c8f9034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 3, 100, 100)]     0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 8, 100, 100)       608       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 8, 100, 100)      400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_1 (MaxPooling2D)    (None, 8, 50, 50)         0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 8, 50, 50)         0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 16, 50, 50)        1168      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 16, 50, 50)       200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_2 (MaxPooling2D)    (None, 16, 25, 25)        0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 16, 25, 25)        0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 32, 25, 25)        4640      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 32, 25, 25)       100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_3 (MaxPooling2D)    (None, 32, 12, 12)        0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 32, 12, 12)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               2359808   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,516,879\n",
      "Trainable params: 2,516,529\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining model layers, build with the Functional API\n",
    "\n",
    "#(channels, rows, cols)\n",
    "input_shape = (3, 100, 100)\n",
    "\n",
    "# Constraints for layer 1\n",
    "# input: tensors of shape (color_channels, image_height, image_width), ignoring batch size\n",
    "x = Input(shape=input_shape)\n",
    "#For CNN: Convolution typically uses 3x3 windows, stride 1 & with padding. Will try 5x5 window first to attempt tp catch more features, but try multiple\n",
    "c0 = Conv2D(8, (5, 5), activation='relu', strides=(1, 1), padding='same', data_format='channels_first', name='conv_1')(x)\n",
    "# normalize input for first layer & also apply to each of the hidden layers\n",
    "b0 = BatchNormalization()(c0)\n",
    "#For CNN: pooling typically uses 2x2 windows, stride 2 & no padding\n",
    "d0 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_first', name='maxpool_1')(b0)\n",
    "e0 = Dropout(0.5)(d0)\n",
    "\n",
    "# Constraints for layer 2\n",
    "c1 = Conv2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same', data_format='channels_first', name='conv_2')(e0)\n",
    "b1 = BatchNormalization()(c1)\n",
    "d1 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_first', name='maxpool_2')(b1)\n",
    "e1 = Dropout(0.5)(d1)\n",
    "\n",
    "# Constraints for layer 3\n",
    "c2 = Conv2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same', data_format='channels_first', name='conv_3')(e1)\n",
    "b2 = BatchNormalization()(c2)\n",
    "d2 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_first', name='maxpool_3')(b2)\n",
    "e2 = Dropout(0.5)(d2)\n",
    "\n",
    "#flatten (or unroll) the 3D output to 1D\n",
    "f = Flatten()(e2)\n",
    "\n",
    "# hidden layer\n",
    "# Dense layer: takes 1D vector as input, current output is a 3D tensor; start simple, then change unit to try to increase performance\n",
    "z0 = Dense(512, activation='relu', kernel_regularizer=l2(0.0001), name='dense_1')(f)\n",
    "z1 = Dense(256, activation='relu', kernel_regularizer=l2(0.0001), name='dense_2')(z0)\n",
    "# use L2 regulization: take sum of all params squared & add it w/ square difference of actual output & predictions\n",
    "# weights not sparse, will get much better accuracy than L1\n",
    "z2 = Dense(64, activation='relu', kernel_regularizer=l2(0.0001), name='dense_3')(z1)\n",
    "z3 = Dense(32, activation='relu', kernel_regularizer=l2(0.0001), name='dense_4')(z2)\n",
    "# output layer must create 3 output values, one for each class\n",
    "# use “softmax” activation function to ensure output values are in range 0-1 & may be used as predicted probabilities\n",
    "y = Dense(NUM_CLASSES, activation='softmax', name='output')(z3)\n",
    "\n",
    "model1 = Model(inputs=x, outputs=y, name=\"model_1\")\n",
    "\n",
    "# Compile Model\n",
    "optimizer = 'adam'\n",
    "metrics = ['accuracy']\n",
    "# Multi-Class Cross-Entropy Loss\n",
    "loss = 'categorical_crossentropy' \n",
    "\n",
    "model1.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa4304fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c851560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitoring validation loss as this tends to be more sensitive\n",
    "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5),\n",
    "     ModelCheckpoint(filepath='best_weights.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True),\n",
    "    BackupAndRestore(backup_dir=\"model1/backup\")] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0cf3cf9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2050 - accuracy: 0.4201WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 70s 382ms/step - loss: 1.2050 - accuracy: 0.4201 - val_loss: 1.1963 - val_accuracy: 0.4253\n",
      "Epoch 2/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1846 - accuracy: 0.4219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 373ms/step - loss: 1.1846 - accuracy: 0.4219 - val_loss: 1.1873 - val_accuracy: 0.4268\n",
      "Epoch 3/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1666 - accuracy: 0.4247WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 373ms/step - loss: 1.1666 - accuracy: 0.4247 - val_loss: 1.1615 - val_accuracy: 0.4268\n",
      "Epoch 4/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1521 - accuracy: 0.4232WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 373ms/step - loss: 1.1521 - accuracy: 0.4232 - val_loss: 1.1457 - val_accuracy: 0.4268\n",
      "Epoch 5/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1414 - accuracy: 0.4236WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 68s 372ms/step - loss: 1.1414 - accuracy: 0.4236 - val_loss: 1.1363 - val_accuracy: 0.4268\n",
      "Epoch 6/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1328 - accuracy: 0.4236WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 71s 385ms/step - loss: 1.1328 - accuracy: 0.4236 - val_loss: 1.1271 - val_accuracy: 0.4262\n",
      "Epoch 7/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1228 - accuracy: 0.4259WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 376ms/step - loss: 1.1228 - accuracy: 0.4259 - val_loss: 1.1192 - val_accuracy: 0.4268\n",
      "Epoch 8/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1164 - accuracy: 0.4256WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 70s 379ms/step - loss: 1.1164 - accuracy: 0.4256 - val_loss: 1.1128 - val_accuracy: 0.4268\n",
      "Epoch 9/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1105 - accuracy: 0.4255WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 375ms/step - loss: 1.1105 - accuracy: 0.4255 - val_loss: 1.1074 - val_accuracy: 0.4268\n",
      "Epoch 10/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1058 - accuracy: 0.4258WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 375ms/step - loss: 1.1058 - accuracy: 0.4258 - val_loss: 1.1032 - val_accuracy: 0.4268\n",
      "Epoch 11/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1023 - accuracy: 0.4256WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 70s 378ms/step - loss: 1.1023 - accuracy: 0.4256 - val_loss: 1.0999 - val_accuracy: 0.4268\n",
      "Epoch 12/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0991 - accuracy: 0.4259WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 377ms/step - loss: 1.0991 - accuracy: 0.4259 - val_loss: 1.0982 - val_accuracy: 0.4268\n",
      "Epoch 13/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0962 - accuracy: 0.4259WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 375ms/step - loss: 1.0962 - accuracy: 0.4259 - val_loss: 1.0944 - val_accuracy: 0.4268\n",
      "Epoch 14/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0934 - accuracy: 0.4259WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 375ms/step - loss: 1.0934 - accuracy: 0.4259 - val_loss: 1.0931 - val_accuracy: 0.4268\n",
      "Epoch 15/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0916 - accuracy: 0.4257WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 377ms/step - loss: 1.0916 - accuracy: 0.4257 - val_loss: 1.0910 - val_accuracy: 0.4268\n",
      "Epoch 16/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0903 - accuracy: 0.4258WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 374ms/step - loss: 1.0903 - accuracy: 0.4258 - val_loss: 1.0892 - val_accuracy: 0.4268\n",
      "Epoch 17/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0881 - accuracy: 0.4259WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 68s 372ms/step - loss: 1.0881 - accuracy: 0.4259 - val_loss: 1.0880 - val_accuracy: 0.4262\n",
      "Epoch 18/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0879 - accuracy: 0.4249WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 377ms/step - loss: 1.0879 - accuracy: 0.4249 - val_loss: 1.0872 - val_accuracy: 0.4268\n",
      "Epoch 19/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0861 - accuracy: 0.4257WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 377ms/step - loss: 1.0861 - accuracy: 0.4257 - val_loss: 1.0861 - val_accuracy: 0.4262\n",
      "Epoch 20/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0851 - accuracy: 0.4259WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 374ms/step - loss: 1.0851 - accuracy: 0.4259 - val_loss: 1.0855 - val_accuracy: 0.4268\n",
      "Epoch 21/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0853 - accuracy: 0.4252WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 376ms/step - loss: 1.0853 - accuracy: 0.4252 - val_loss: 1.0854 - val_accuracy: 0.4268\n",
      "Epoch 22/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0842 - accuracy: 0.4271WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 375ms/step - loss: 1.0842 - accuracy: 0.4271 - val_loss: 1.0865 - val_accuracy: 0.4268\n",
      "Epoch 23/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0848 - accuracy: 0.4275WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 70s 378ms/step - loss: 1.0848 - accuracy: 0.4275 - val_loss: 1.0891 - val_accuracy: 0.4212\n",
      "Epoch 24/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0861 - accuracy: 0.4253WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 376ms/step - loss: 1.0861 - accuracy: 0.4253 - val_loss: 1.0879 - val_accuracy: 0.4238\n",
      "Epoch 25/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0851 - accuracy: 0.4279WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 375ms/step - loss: 1.0851 - accuracy: 0.4279 - val_loss: 1.0878 - val_accuracy: 0.4259\n",
      "Epoch 26/100\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0860 - accuracy: 0.4291WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 376ms/step - loss: 1.0860 - accuracy: 0.4291 - val_loss: 1.0910 - val_accuracy: 0.4277\n",
      "Epoch 26: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train Model 1\n",
    "history = model1.fit(\n",
    "                    X_train_1, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=NUM_EPOCH,\n",
    "                    validation_data=(X_valid_1, Y_valid),                \n",
    "                    shuffle=True,\n",
    "                    callbacks=es\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72be6614-8e0b-41a3-89be-75a58efd7adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1/assets\n"
     ]
    }
   ],
   "source": [
    "model1.save('model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e4cb910-58cc-4885-bc93-9c045bb3866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0969 - accuracy: 0.4134\n",
      "accuracy: 41.34%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "score = model1.evaluate(X_test_1, Y_test, verbose=True)\n",
    "print(\"%s: %.2f%%\" % (model1.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1091275b-39b0-41e2-8677-651eac597884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1145 - accuracy: 0.3467\n",
      "accuracy: 34.67%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test smaller subset\n",
    "score = model1.evaluate(X_test_1_sub, Y_test_sub, verbose=True)\n",
    "print(\"%s: %.2f%%\" % (model1.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a17339-82d0-4bdd-9ded-fe3e66a29111",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualizing training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1edc620a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2bd017ac0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 279,
       "width": 424
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = list(range(len(loss)))\n",
    "\n",
    "#plot\n",
    "figsize=(6,4)\n",
    "fig, axis1 = plt.subplots(figsize=figsize)\n",
    "\n",
    "plot1_lacc = axis1.plot(epochs, acc, 'navy', label='accuracy')\n",
    "plot1_val_lacc = axis1.plot(epochs, val_acc, 'deepskyblue', label=\"Validation Accuracy\")\n",
    "\n",
    "plot1_loss = axis1.plot(epochs, loss, 'red', label='loss')\n",
    "plot1_val_loss = axis1.plot(epochs, val_loss, 'lightsalmon', label=\"Validation Loss\")\n",
    "\n",
    "\n",
    "plots = plot1_loss + plot1_val_loss\n",
    "labs = [l.get_label() for l in plots]\n",
    "\n",
    "axis1.set_xlabel('Epoch')\n",
    "axis1.set_ylabel('Loss/Accuracy')\n",
    "plt.title(\"Model 1 Loss/Accuracy History (Year 1 Images)\")\n",
    "plt.tight_layout()\n",
    "axis1.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3dbe98-6dd8-42e7-bdc8-9b1ffe0fadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model1.predict(X_test_1)\n",
    "pred = np.round(prob, 0).astype('int32')\n",
    "\n",
    "# Classification report\n",
    "classification_metrics = classification_report(Y_test, pred, target_names=class_names)\n",
    "pprint(classification_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1848f65-599a-438f-a5c7-be97248a1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, Precision, Recall scores\n",
    "labels = [0, 1, 2]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, pred, labels=labels, average='samples')\n",
    "print('Precision (samples): %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y_test, pred, labels=labels, average='samples')\n",
    "print('Recall (samples): %f' % recall)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, pred, labels=labels, average='micro')\n",
    "print('Precision (micro): %f' % precision)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, pred, labels=labels, average='weighted')\n",
    "print('Precision (weighted): %f' % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280ee8f7-20ec-4625-bf5e-277ec42b9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Confusion matrix\n",
    "categorical_test_labels = pd.DataFrame(Y_test).idxmax(axis=1)\n",
    "categorical_preds = pd.DataFrame(pred).idxmax(axis=1)\n",
    "confusion_matrix = confusion_matrix(categorical_test_labels, categorical_preds)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "   normalize=False,\n",
    "   title='Confusion Matrix',\n",
    "   cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label') \n",
    "    \n",
    "plot_confusion_matrix(confusion_matrix, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937053d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model 2\n",
    "Changes:\n",
    "\n",
    "Added image augmentation\n",
    "\n",
    "Increased dropout rates to 0.8 after first dropout layer\n",
    "\n",
    "Increased the number of layers and filter size\n",
    "\n",
    "Added padding to Maxpool\n",
    "\n",
    "Added callback to change Learning rate at plateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "472a7e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 3, 100, 100)]     0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 64, 100, 100)      4864      \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 64, 100, 100)      36928     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 64, 100, 100)     400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_1 (MaxPooling2D)    (None, 64, 50, 50)        0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 64, 50, 50)        0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 128, 50, 50)       73856     \n",
      "                                                                 \n",
      " conv_4 (Conv2D)             (None, 128, 50, 50)       147584    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 128, 50, 50)      200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_2 (MaxPooling2D)    (None, 128, 25, 25)       0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128, 25, 25)       0         \n",
      "                                                                 \n",
      " conv_5 (Conv2D)             (None, 256, 25, 25)       295168    \n",
      "                                                                 \n",
      " conv_6 (Conv2D)             (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " conv_7 (Conv2D)             (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 256, 25, 25)      100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_3 (MaxPooling2D)    (None, 256, 13, 13)       0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 256, 13, 13)       0         \n",
      "                                                                 \n",
      " conv_8 (Conv2D)             (None, 512, 13, 13)       1180160   \n",
      "                                                                 \n",
      " conv_9 (Conv2D)             (None, 512, 13, 13)       2359808   \n",
      "                                                                 \n",
      " conv_10 (Conv2D)            (None, 512, 13, 13)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 512, 13, 13)      52        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_4 (MaxPooling2D)    (None, 512, 7, 7)         0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512, 7, 7)         0         \n",
      "                                                                 \n",
      " conv_11 (Conv2D)            (None, 512, 7, 7)         2359808   \n",
      "                                                                 \n",
      " conv_12 (Conv2D)            (None, 512, 7, 7)         2359808   \n",
      "                                                                 \n",
      " conv_13 (Conv2D)            (None, 512, 7, 7)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 512, 7, 7)        28        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_5 (MaxPooling2D)    (None, 512, 4, 4)         0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512, 4, 4)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              33558528  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 3003      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,158,383\n",
      "Trainable params: 69,157,993\n",
      "Non-trainable params: 390\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (3, 100, 100)\n",
    "\n",
    "# Constraints for block 1\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same', data_format='channels_first', name='conv_1')(inputs)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_1')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "# Constraints for block 2\n",
    "x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_3')(x)\n",
    "x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_4')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_2')(x)\n",
    "x = Dropout(rate=0.8)(x)\n",
    "\n",
    "# Constraints for block 3\n",
    "x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_5')(x)\n",
    "x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_6')(x)\n",
    "x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_7')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_3')(x)\n",
    "x = Dropout(rate=0.8)(x)\n",
    "\n",
    "# Constraints for block 4\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_8')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_9')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_10')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_4')(x)\n",
    "x = Dropout(rate=0.8)(x)\n",
    "\n",
    "# Constraints for block 5\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_11')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_12')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_13')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_5')(x)\n",
    "x = Dropout(rate=0.8)(x)\n",
    "\n",
    "# flatten (or unroll) the 3D output to 1D\n",
    "x = Flatten()(x)\n",
    "\n",
    "# hidden layers\n",
    "x = Dense(4096, activation='relu', kernel_regularizer=l2(0.0001), name='dense_1')(x)\n",
    "x = Dense(4096, activation='relu', kernel_regularizer=l2(0.0001), name='dense_2')(x)\n",
    "x = Dense(1000, activation='relu', kernel_regularizer=l2(0.0001), name='dense_3')(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax', name='output')(x)\n",
    "\n",
    "model2 = Model(inputs=inputs, outputs=outputs, name=\"model_2\")\n",
    "\n",
    "# Compile model\n",
    "model2.compile( \n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a37e7fd9-9809-434b-8531-f190e5a2b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=90,\n",
    "      width_shift_range=0.2,               \n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      vertical_flip = True,\n",
    "      horizontal_flip=True)\n",
    "\n",
    "image_gen_valid = ImageDataGenerator(\n",
    "      rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2827bc4b-51ca-4bfa-9d2d-8aaf9249248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainImage = image_gen_train.flow(x=X_train_1, y=Y_train)\n",
    "\n",
    "ValidImage = image_gen_valid.flow(x=X_valid_1, y=Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90a6d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5),\n",
    "      ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=5),\n",
    "      BackupAndRestore(backup_dir='backups'),\n",
    "# Save best weights in order to maximize validation accuracy, only saves when the model is considered the \"best\"\n",
    "      ModelCheckpoint(filepath='best_weights.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b89d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "NUM_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6abca1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 10:20:50.312010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - ETA: 0s - loss: 2.1122 - accuracy: 0.4187"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 10:33:39.348530: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 787s 1s/step - loss: 2.1122 - accuracy: 0.4187 - val_loss: 1.5917 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.4284 - accuracy: 0.4230WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 794s 1s/step - loss: 1.4284 - accuracy: 0.4230 - val_loss: 1.2944 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.2348 - accuracy: 0.4248WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 793s 1s/step - loss: 1.2348 - accuracy: 0.4248 - val_loss: 1.1815 - val_accuracy: 0.4221 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.1511 - accuracy: 0.4250WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 797s 1s/step - loss: 1.1511 - accuracy: 0.4250 - val_loss: 1.1230 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.1072 - accuracy: 0.4265WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 809s 1s/step - loss: 1.1072 - accuracy: 0.4265 - val_loss: 1.0958 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.1042 - accuracy: 0.4256WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 797s 1s/step - loss: 1.1042 - accuracy: 0.4256 - val_loss: 1.0894 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0843 - accuracy: 0.4264WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 800s 1s/step - loss: 1.0843 - accuracy: 0.4264 - val_loss: 1.0795 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0775 - accuracy: 0.4265WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 805s 1s/step - loss: 1.0775 - accuracy: 0.4265 - val_loss: 1.0758 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0749 - accuracy: 0.4265WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 803s 1s/step - loss: 1.0749 - accuracy: 0.4265 - val_loss: 1.0742 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0739 - accuracy: 0.4265WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 806s 1s/step - loss: 1.0739 - accuracy: 0.4265 - val_loss: 1.0734 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0735 - accuracy: 0.4264WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 804s 1s/step - loss: 1.0735 - accuracy: 0.4264 - val_loss: 1.0734 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0755 - accuracy: 0.4262WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 806s 1s/step - loss: 1.0755 - accuracy: 0.4262 - val_loss: 1.0735 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0735 - accuracy: 0.4265WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 809s 1s/step - loss: 1.0735 - accuracy: 0.4265 - val_loss: 1.0732 - val_accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "557/734 [=====================>........] - ETA: 14:51 - loss: 1.0727 - accuracy: 0.4268"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTrainImage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mValidImage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history2 =  model2.fit(TrainImage,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=NUM_EPOCH,\n",
    "                    validation_data=ValidImage,\n",
    "                    shuffle=True,\n",
    "                    verbose=True,\n",
    "                    callbacks=es\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cdcf99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 35s 163ms/step - loss: 1.0731 - accuracy: 0.4264\n",
      "accuracy: 42.64%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_score = model2.evaluate(X_test_1, Y_test, verbose=True)\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], test_score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96978cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 153ms/step - loss: 1.1251 - accuracy: 0.3333\n",
      "accuracy: 33.33%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test smaller subset\n",
    "test_sub_score = model2.evaluate(X_test_1_sub, Y_test_sub, verbose=True)\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], test_sub_score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bda994-713f-4dbf-b4ba-6629415679bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualizing training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f6c70e-a3c3-4a16-90f0-98f4f015222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc = history2.history['accuracy']\n",
    "val_acc = history2.history['val_accuracy']\n",
    "\n",
    "# Loss\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "epochs = list(range(len(loss)))\n",
    "\n",
    "#plot\n",
    "figsize=(6,4)\n",
    "fig, axis1 = plt.subplots(figsize=figsize)\n",
    "\n",
    "plot1_lacc = axis1.plot(epochs, acc, 'navy', label='accuracy')\n",
    "plot1_val_lacc = axis1.plot(epochs, val_acc, 'deepskyblue', label=\"Validation Accuracy\")\n",
    "\n",
    "plot1_loss = axis1.plot(epochs, loss, 'red', label='loss')\n",
    "plot1_val_loss = axis1.plot(epochs, val_loss, 'lightsalmon', label=\"Validation Loss\")\n",
    "\n",
    "\n",
    "plots = plot1_loss + plot1_val_loss\n",
    "labs = [l.get_label() for l in plots]\n",
    "\n",
    "axis1.set_xlabel('Epoch')\n",
    "axis1.set_ylabel('Loss/Accuracy')\n",
    "plt.title(\"Model 2 Loss/Accuracy History (Year 1 Images)\")\n",
    "plt.tight_layout()\n",
    "axis1.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba13555-cad7-4f74-952f-baffe4ff0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model2.predict(X_test_1)\n",
    "pred = np.round(prob, 0).astype('int32')\n",
    "\n",
    "# Classification report\n",
    "classification_metrics = classification_report(Y_test, pred, target_names=class_names)\n",
    "pprint(classification_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f08efd-3c6b-43f6-a765-bee0dcda0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, Precision, Recall scores\n",
    "labels = [0, 1, 2]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, pred, labels=labels, average='samples')\n",
    "print('Precision (samples): %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y_test, pred, labels=labels, average='samples')\n",
    "print('Recall (samples): %f' % recall)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, pred, labels=labels, average='micro')\n",
    "print('Precision (micro): %f' % precision)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, pred, labels=labels, average='weighted')\n",
    "print('Precision (weighted): %f' % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4cfde-9576-4280-b451-ef98950c2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Confusion matrix\n",
    "categorical_test_labels = pd.DataFrame(Y_test).idxmax(axis=1)\n",
    "categorical_preds = pd.DataFrame(pred).idxmax(axis=1)\n",
    "confusion_matrix = confusion_matrix(categorical_test_labels, categorical_preds)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "   normalize=False,\n",
    "   title='Confusion Matrix',\n",
    "   cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label') \n",
    "    \n",
    "plot_confusion_matrix(confusion_matrix, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d470cf-bb1e-4090-9312-041f7eaa1e69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model 3\n",
    "changes:\n",
    "\n",
    "edit dropout placement and size\n",
    "\n",
    "decrease batch size\n",
    "\n",
    "edit image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dfed62d-bef1-464b-90cf-3119cf5302a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 3, 100, 100)]     0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 64, 100, 100)      4864      \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 64, 100, 100)      36928     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 64, 100, 100)     400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_1 (MaxPooling2D)    (None, 64, 50, 50)        0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 64, 50, 50)        0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 128, 50, 50)       73856     \n",
      "                                                                 \n",
      " conv_4 (Conv2D)             (None, 128, 50, 50)       147584    \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 128, 50, 50)      200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_2 (MaxPooling2D)    (None, 128, 25, 25)       0         \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 128, 25, 25)       0         \n",
      "                                                                 \n",
      " conv_5 (Conv2D)             (None, 256, 25, 25)       295168    \n",
      "                                                                 \n",
      " conv_6 (Conv2D)             (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " conv_7 (Conv2D)             (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 256, 25, 25)      100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_3 (MaxPooling2D)    (None, 256, 13, 13)       0         \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 256, 13, 13)       0         \n",
      "                                                                 \n",
      " conv_8 (Conv2D)             (None, 512, 13, 13)       1180160   \n",
      "                                                                 \n",
      " conv_9 (Conv2D)             (None, 512, 13, 13)       2359808   \n",
      "                                                                 \n",
      " conv_10 (Conv2D)            (None, 512, 13, 13)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 512, 13, 13)      52        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_4 (MaxPooling2D)    (None, 512, 7, 7)         0         \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 512, 7, 7)         0         \n",
      "                                                                 \n",
      " conv_11 (Conv2D)            (None, 512, 7, 7)         2359808   \n",
      "                                                                 \n",
      " conv_12 (Conv2D)            (None, 512, 7, 7)         2359808   \n",
      "                                                                 \n",
      " conv_13 (Conv2D)            (None, 512, 7, 7)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 512, 7, 7)        28        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_5 (MaxPooling2D)    (None, 512, 4, 4)         0         \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 512, 4, 4)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              33558528  \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 1000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 3003      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,158,383\n",
      "Trainable params: 69,157,993\n",
      "Non-trainable params: 390\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (3, 100, 100)\n",
    "\n",
    "# Constraints for block 1\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same', data_format='channels_first', name='conv_1')(inputs)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_1')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "# Constraints for block 2\n",
    "x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_3')(x)\n",
    "x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_4')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_2')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "# Constraints for block 3\n",
    "x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_5')(x)\n",
    "x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_6')(x)\n",
    "x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_7')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_3')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "# Constraints for block 4\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_8')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_9')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_10')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_4')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "# Constraints for block 5\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_11')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_12')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_13')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_5')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "# flatten (or unroll) the 3D output to 1D\n",
    "x = Flatten()(x)\n",
    "\n",
    "# hidden layers\n",
    "x = Dense(4096, activation='relu', kernel_regularizer=l2(0.0001), name='dense_1')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(4096, activation='relu', kernel_regularizer=l2(0.0001), name='dense_2')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(1000, activation='relu', kernel_regularizer=l2(0.0001), name='dense_3')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax', name='output')(x)\n",
    "\n",
    "model3 = Model(inputs=inputs, outputs=outputs, name=\"model_3\")\n",
    "\n",
    "# Compile model\n",
    "model3.compile( \n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fef59eb1-2e6e-470a-b2dc-124d66603eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=90,\n",
    "      width_shift_range=0.6,               \n",
    "      height_shift_range=0.6,\n",
    "      shear_range=0.6,\n",
    "      zoom_range=0.6,\n",
    "      vertical_flip = True,\n",
    "      horizontal_flip = True)\n",
    "\n",
    "image_gen_valid = ImageDataGenerator(\n",
    "      rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b4d1e9c-6b4f-4fb5-9e7a-0b29ad3390dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5),\n",
    "      ModelCheckpoint(filepath='best_weights.h5', monitor='val_acc', mode='max', \n",
    "        save_best_only=True)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e721cd34-b6d2-45c7-95ee-b57639646b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "NUM_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6918542-ade1-4dd8-b525-d968063e4025",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 2.0023 - accuracy: 0.4142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 19:45:04.147918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 794s 1s/step - loss: 2.0023 - accuracy: 0.4142 - val_loss: 1.6703 - val_accuracy: 0.4268\n",
      "Epoch 2/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.5101 - accuracy: 0.4236WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 788s 1s/step - loss: 1.5101 - accuracy: 0.4236 - val_loss: 1.4335 - val_accuracy: 0.4009\n",
      "Epoch 3/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.3240 - accuracy: 0.4224WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 796s 1s/step - loss: 1.3240 - accuracy: 0.4224 - val_loss: 1.2526 - val_accuracy: 0.4268\n",
      "Epoch 4/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.2242 - accuracy: 0.4246WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 800s 1s/step - loss: 1.2242 - accuracy: 0.4246 - val_loss: 1.1701 - val_accuracy: 0.4268\n",
      "Epoch 5/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.1481 - accuracy: 0.4253WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 789s 1s/step - loss: 1.1481 - accuracy: 0.4253 - val_loss: 1.1280 - val_accuracy: 0.4268\n",
      "Epoch 6/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.1134 - accuracy: 0.4246WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 793s 1s/step - loss: 1.1134 - accuracy: 0.4246 - val_loss: 1.0993 - val_accuracy: 0.4268\n",
      "Epoch 7/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0931 - accuracy: 0.4253WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 794s 1s/step - loss: 1.0931 - accuracy: 0.4253 - val_loss: 1.0863 - val_accuracy: 0.4268\n",
      "Epoch 8/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0867 - accuracy: 0.4254WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 793s 1s/step - loss: 1.0867 - accuracy: 0.4254 - val_loss: 1.0811 - val_accuracy: 0.4268\n",
      "Epoch 9/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0834 - accuracy: 0.4252WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 797s 1s/step - loss: 1.0834 - accuracy: 0.4252 - val_loss: 1.0788 - val_accuracy: 0.4268\n",
      "Epoch 10/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0771 - accuracy: 0.4263WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 794s 1s/step - loss: 1.0771 - accuracy: 0.4263 - val_loss: 1.0756 - val_accuracy: 0.4268\n",
      "Epoch 11/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0768 - accuracy: 0.4258WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 792s 1s/step - loss: 1.0768 - accuracy: 0.4258 - val_loss: 1.0747 - val_accuracy: 0.4268\n",
      "Epoch 12/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.4264WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 810s 1s/step - loss: 1.0747 - accuracy: 0.4264 - val_loss: 1.0738 - val_accuracy: 0.4268\n",
      "Epoch 13/100\n",
      "734/734 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.4263WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "734/734 [==============================] - 798s 1s/step - loss: 1.0747 - accuracy: 0.4263 - val_loss: 1.0753 - val_accuracy: 0.4268\n",
      "Epoch 14/100\n",
      "347/734 [=============>................] - ETA: 26:10 - loss: 1.0742 - accuracy: 0.4339"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model 3 on batches with data augmentation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history3 \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_gen_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_gen_valid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model 3 on batches with data augmentation\n",
    "history3 = model3.fit(image_gen_train.flow(X_train_1, Y_train),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=NUM_EPOCH,\n",
    "                    validation_data=image_gen_valid.flow(X_valid_1, Y_valid),\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=es\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6524cee-8ec9-471e-93fd-832e3ecab0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model3/assets\n"
     ]
    }
   ],
   "source": [
    "model3.save('model3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1f9eb7-ae29-4577-a543-370dcb7821d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualizing training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dce9ad4e-3c89-4236-a4f2-a3821b665613",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory3\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history3\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history3' is not defined"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc = history3.history['accuracy']\n",
    "val_acc = history3.history['val_accuracy']\n",
    "\n",
    "# Loss\n",
    "loss = history3.history['loss']\n",
    "val_loss = history3.history['val_loss']\n",
    "\n",
    "epochs = list(range(len(loss)))\n",
    "\n",
    "#plot\n",
    "figsize=(6,4)\n",
    "fig, axis1 = plt.subplots(figsize=figsize)\n",
    "\n",
    "plot1_lacc = axis1.plot(epochs, acc, 'navy', label='accuracy')\n",
    "plot1_val_lacc = axis1.plot(epochs, val_acc, 'deepskyblue', label=\"Validation Accuracy\")\n",
    "\n",
    "plot1_loss = axis1.plot(epochs, loss, 'red', label='loss')\n",
    "plot1_val_loss = axis1.plot(epochs, val_loss, 'lightsalmon', label=\"Validation Loss\")\n",
    "\n",
    "\n",
    "plots = plot1_loss + plot1_val_loss\n",
    "labs = [l.get_label() for l in plots]\n",
    "\n",
    "axis1.set_xlabel('Epoch')\n",
    "axis1.set_ylabel('Loss/Accuracy')\n",
    "plt.title(\"Model 3 Loss/Accuracy History (Year 1 Images)\")\n",
    "plt.tight_layout()\n",
    "axis1.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa9f6074-dd51-4f03-8f7b-6e2da90b3aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 23:13:49.017123: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72/210 [=========>....................] - ETA: 21s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(prob, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Classification report\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/engine/training.py:2033\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2032\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2033\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2034\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2035\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prob = model3.predict(X_test_1)\n",
    "pred = np.round(prob, 0).astype('int32')\n",
    "\n",
    "# Classification report\n",
    "classification_metrics = classification_report(Y_test, pred, target_names=class_names)\n",
    "pprint(classification_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2b46d-9bfd-434f-8e5a-5d8df91881af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, Precision, Recall scores\n",
    "labels = [0, 1, 2]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, pred, labels=labels, average='samples')\n",
    "print('Precision (samples): %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y_test, pred, labels=labels, average='samples')\n",
    "print('Recall (samples): %f' % recall)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, pred, labels=labels, average='micro')\n",
    "print('Precision (micro): %f' % precision)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, pred, labels=labels, average='weighted')\n",
    "print('Precision (weighted): %f' % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f530c36-b124-44a6-8d07-d9d99dc47542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Confusion matrix\n",
    "categorical_test_labels = pd.DataFrame(Y_test).idxmax(axis=1)\n",
    "categorical_preds = pd.DataFrame(pred).idxmax(axis=1)\n",
    "confusion_matrix = confusion_matrix(categorical_test_labels, categorical_preds)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "   normalize=False,\n",
    "   title='Confusion Matrix',\n",
    "   cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label') \n",
    "    \n",
    "plot_confusion_matrix(confusion_matrix, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c14c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Extra model (if time allows)\n",
    "Changes:\n",
    "\n",
    "edit to look more like Resnet50 architecture, including adding zero-padding but keep dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b25ce797-091a-4fd0-8fe9-ed7dd35d8fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 3, 100, 100)]     0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 64, 100, 100)      4864      \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 64, 100, 100)      36928     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 64, 100, 100)     400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_1 (MaxPooling2D)    (None, 64, 50, 50)        0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64, 50, 50)        0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 128, 50, 50)       73856     \n",
      "                                                                 \n",
      " conv_4 (Conv2D)             (None, 128, 50, 50)       147584    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128, 50, 50)      200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_2 (MaxPooling2D)    (None, 128, 25, 25)       0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128, 25, 25)       0         \n",
      "                                                                 \n",
      " conv_5 (Conv2D)             (None, 256, 25, 25)       295168    \n",
      "                                                                 \n",
      " conv_6 (Conv2D)             (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " conv_7 (Conv2D)             (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 256, 25, 25)      100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_3 (MaxPooling2D)    (None, 256, 13, 13)       0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 256, 13, 13)       0         \n",
      "                                                                 \n",
      " conv_8 (Conv2D)             (None, 512, 13, 13)       1180160   \n",
      "                                                                 \n",
      " conv_9 (Conv2D)             (None, 512, 13, 13)       2359808   \n",
      "                                                                 \n",
      " conv_10 (Conv2D)            (None, 512, 13, 13)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 512, 13, 13)      52        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_4 (MaxPooling2D)    (None, 512, 7, 7)         0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512, 7, 7)         0         \n",
      "                                                                 \n",
      " conv_11 (Conv2D)            (None, 512, 7, 7)         2359808   \n",
      "                                                                 \n",
      " conv_12 (Conv2D)            (None, 512, 7, 7)         2359808   \n",
      "                                                                 \n",
      " conv_13 (Conv2D)            (None, 512, 7, 7)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 512, 7, 7)        28        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool_5 (MaxPooling2D)    (None, 512, 4, 4)         0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512, 4, 4)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              33558528  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 3003      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,158,383\n",
      "Trainable params: 69,157,993\n",
      "Non-trainable params: 390\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (3, 100, 100)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Dropout(rate=0.8)(x)\n",
    "#block1\n",
    "# Zero-Padding\n",
    "x = ZeroPadding2D((3, 3))(inputs)\n",
    "x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), data_format='channels_first', name='conv_1')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), data_format='channels_first', name='maxpool_1')(x)\n",
    "\n",
    "\n",
    "#block2 - c\n",
    "X = Conv2D(64, (1, 1), strides = (1,1))(x)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(filters = 256, kernel_size = (1, 1), strides = (s,s), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block3 - i\n",
    "X = Conv2D(filters = 64, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "#block4 - i\n",
    "X = Conv2D(filters = 64, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block5 - c\n",
    "X = Conv2D(128, (1, 1), strides = (2,2))(x)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 512, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(filters = 512, kernel_size = (1, 1), strides = (2,2), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 6 - i\n",
    "X = Conv2D(filters = 128, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 512, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 7 - i\n",
    "X = Conv2D(filters = 128, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 512, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 8 - i\n",
    "X = Conv2D(filters = 128, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 512, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 9 - c\n",
    "X = Conv2D(256, (1, 1), strides = (2,2))(x)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 1024, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(filters = 1024, kernel_size = (1, 1), strides = (2,2), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 10 - i\n",
    "X = Conv2D(filters = 256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 1024, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 11 - i\n",
    "X = Conv2D(filters = 256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 1024, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 12 - i\n",
    "X = Conv2D(filters = 256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 1024, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 13 - i\n",
    "X = Conv2D(filters = 256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 1024, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 14 - i\n",
    "X = Conv2D(filters = 256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 1024, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 15 - c\n",
    "X = Conv2D(512, (1, 1), strides = (2,2))(x)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 2048, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(filters = 2048, kernel_size = (1, 1), strides = (2,2), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 16 - i\n",
    "X = Conv2D(filters = 512, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 2048, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "# block 17 - i\n",
    "X = Conv2D(filters = 512, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1,1), padding = 'same')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Conv2D(filters = 2048, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "# flatten (or unroll) the 3D output to 1D\n",
    "x = Flatten()(X)\n",
    "\n",
    "# hidden layers\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax', name='output')(x)\n",
    "\n",
    "model4 = Model(inputs=inputs, outputs=outputs, name=\"model_4\")\n",
    "\n",
    "# Compile model\n",
    "model4.compile( \n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c8a7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5),\n",
    "      ModelCheckpoint(filepath='best_weights.h5', monitor='val_acc', mode='max', \n",
    "        save_best_only=True)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "420012bb-640b-4e6f-aba7-ad0d28c08d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "NUM_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ada64ed0-31ff-4041-9e38-6a655d2430e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 18:32:51.616880: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64/734 [=>............................] - ETA: 11:46 - loss: 3.2296 - accuracy: 0.3789"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model 3 on batches with data augmentation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_gen_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_gen_valid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/engine/training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1414\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1416\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/utils/tf_utils.py:607\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    605\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/util/nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    913\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    917\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/util/nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    913\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    917\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/utils/tf_utils.py:601\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 601\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1124\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1126\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model 3 on batches with data augmentation\n",
    "history =  model4.fit(image_gen_train.flow(X_train_1, Y_train),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=NUM_EPOCH,\n",
    "                    validation_data=image_gen_valid.flow(X_valid_1, Y_valid),\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=es\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f15eca0-d4f1-4e3f-947e-9c03c8fc4d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model3/assets\n"
     ]
    }
   ],
   "source": [
    "model4.save('model4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c56440-0638-41e6-8d99-b6022611ced0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Final Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c695921c-147a-498e-8ec4-e69467b5a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use model 2 for now\n",
    "model2.save('model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6532be68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualizing Feature/Activation Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d1a05",
   "metadata": {},
   "source": [
    "#### Visualize for Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c01894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/210 [..............................] - ETA: 51s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 23:21:44.705502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25/210 [==>...........................] - ETA: 2:16:19"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m activation_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mmodel2\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39mlayer_outputs) \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# returns the values of the layer activations in model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Returns a list of Numpy arrays: one array per layer activation\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m activations \u001b[38;5;241m=\u001b[39m \u001b[43mactivation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/engine/training.py:2033\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2032\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2033\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2034\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2035\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Extracts the outputs of all layers except the input layer\n",
    "layer_outputs = [layer.output for layer in model2.layers[1:]]\n",
    "\n",
    "# Creates model that will return these outputs, given the model input\n",
    "activation_model = models.Model(inputs=model2.input, outputs=layer_outputs) \n",
    "\n",
    "# returns the values of the layer activations in model\n",
    "# Returns a list of Numpy arrays: one array per layer activation\n",
    "activations = activation_model.predict(X_test_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation maps for all filters in each convolutional layer\n",
    "fig1=plt.figure(figsize=(10,1.5))  \n",
    "for i in range(64):\n",
    "    plt.subplot(1, 64, i + 1)\n",
    "    layer_activation = activations[0]\n",
    "    plt.imshow(layer_activation[1649, i, :, :], cmap='viridis', aspect='auto')\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "fig2=plt.figure(figsize=(10,3))  \n",
    "for i in range(128):\n",
    "    plt.subplot(2, 128, i + 1)\n",
    "    layer_activation = activations[4]\n",
    "    plt.imshow(layer_activation[1649, i, :, :], cmap='viridis', aspect='auto')\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)\n",
    "    \n",
    "fig3=plt.figure(figsize=(10,6))  \n",
    "for i in range(256):\n",
    "    plt.subplot(4, 256, i + 1)\n",
    "    layer_activation = activations[8]\n",
    "    plt.imshow(layer_activation[1649, i, :, :], cmap='viridis', aspect='auto')\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)\n",
    "    \n",
    "fig4=plt.figure(figsize=(10,9))  \n",
    "for i in range(512):\n",
    "    plt.subplot(4, 512, i + 1)\n",
    "    layer_activation = activations[8]\n",
    "    plt.imshow(layer_activation[1649, i, :, :], cmap='viridis', aspect='auto')\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7493ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 32s 155ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m pred \u001b[38;5;241m=\u001b[39m  (prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(Y_test)):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (Y_test[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pred[i,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m): \u001b[38;5;66;03m# and other Y_test vs pred combinations TP=(1,1), FP=(0,1), TN=(0,0), FN=(1,0)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m (i)\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(Y_test[i],pred[i])\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "prob = model2.predict(X_test_1)\n",
    "pred =  (prob > 0.5).astype('int32') \n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    if (Y_test[i] == 1 and pred[i,0] == 1): # and other Y_test vs pred combinations TP=(1,1), FP=(0,1), TN=(0,0), FN=(1,0)\n",
    "        print (i)\n",
    "        print(Y_test[i],pred[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ba988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print output probabilities for the chosen TP, FP, TN, FN examples\n",
    "\n",
    "# print(prob[84],prob[1370],prob[2031],prob[3003]) # TP examples\n",
    "# print(prob[560],prob[1228],prob[2878],prob[3026]) # FP examples\n",
    "# print(prob[564],prob[1056],prob[2083],prob[3063]) # TN examples\n",
    "# print(prob[465],prob[1546],prob[2241],prob[3037]) # FN examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot examples\n",
    "tp1 = X_test_1[84,1]\n",
    "tp2 = X_test_1[1370,1]\n",
    "tp3 = X_test_1[2031,1]\n",
    "tp4 = X_test_1[3003,1]\n",
    "\n",
    "fp1 = X_test_1[560,1]\n",
    "fp2 = X_test_1[1228,1]\n",
    "fp3 = X_test_1[2878,1]\n",
    "fp4 = X_test_1[3026,1]\n",
    "\n",
    "tn1 = X_test_1[564,1]\n",
    "tn2 = X_test_1[1056,1]\n",
    "tn3 = X_test_1[2083,1]\n",
    "tn4 = X_test_1[3063,1]\n",
    "\n",
    "fn1 = X_test_1[465,1]\n",
    "fn2 = X_test_1[1546,1]\n",
    "fn3 = X_test_1[2241,1]\n",
    "fn4 = X_test_1[3037,1]\n",
    "\n",
    "examples = [tp1, tp2, tp3, tp4, fp1, fp2, fp3, fp4, tn1, tn2, tn3, tn4, fn1, fn2, fn3, fn4]\n",
    "\n",
    "fig1=plt.figure(figsize=(8,8))\n",
    "\n",
    "for i, image in enumerate(examples):\n",
    "    fig1.suptitle('From top row to bottom: TP, FP, TN, FN', fontsize=20)\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image, aspect='auto', cmap='viridis')\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2da41",
   "metadata": {},
   "source": [
    "## Fine Tuning - Transfer Learning with year 10 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf29014-d488-43cb-9ef7-bbe199ce6851",
   "metadata": {},
   "source": [
    "Trying to transfer ability to extract features over to new dataset. Initialize network w/ the weights from saved model, freeze all Conv2D & Max-pooling layers so weights not modified.\n",
    "\n",
    "-We expect this performance to likely be worse since images are noisier.\n",
    "\n",
    "-All images in both source and target domain are labeled: Inductive transfer learning \n",
    "\n",
    "-Using saved model as a fixed feature extractor for noisy data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47fe8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load year 10 train, test, validation image files\n",
    "X_train_10 = np.load('images_Y10_train.npy')\n",
    "X_test_10 = np.load('images_Y10_test.npy')\n",
    "X_valid_10 = np.load('images_Y10_valid.npy')\n",
    "X_test_10_sub = np.load('images_Y10_test_150.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c10bb56c-8295-4fc2-99c2-7a1e82aff4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "random.seed(5)\n",
    "idx = np.random.choice(len(X_train_10), size=len(X_train_10), replace=False)\n",
    "X_train_10 = X_train_10[idx]\n",
    "idx = np.random.choice(len(X_test_10), size=len(X_test_10), replace=False)\n",
    "X_test_10 = X_test_10[idx]\n",
    "idx = np.random.choice(len(X_valid_10), size=len(X_valid_10), replace=False)\n",
    "X_valid_10 = X_valid_10[idx]\n",
    "idx = np.random.choice(len(X_test_10_sub), size=len(X_test_10_sub), replace=False)\n",
    "X_test_10_sub = X_test_10_sub[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c0ea416-b9af-4b47-baff-0415f7e65142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast data types as floats\n",
    "X_train_10 = X_train_10.astype('float32')\n",
    "X_test_10 = X_test_10.astype('float32')\n",
    "X_valid_10 = X_valid_10.astype('float32')\n",
    "X_test_10_sub = X_test_10_sub.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177a9b8-b79d-4a26-9201-effbc2095664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove fully connected layers of model and add to classifier \n",
    "# to fine-tune; make last layer the output\n",
    "model = load_model('model_2')\n",
    "\n",
    "model.trainable = False\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "59a81654-3f7b-42a4-b103-d19046237195",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 3, 100, 100), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\") at layer \"conv_1\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)(x)\n\u001b[1;32m     10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(NUM_CLASSES, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m---> 12\u001b[0m TL_model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer Learning Model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/engine/functional.py:148\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    146\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)]):\n\u001b[1;32m    147\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(inputs, outputs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/engine/functional.py:232\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_coordinates\u001b[38;5;241m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_map_graph_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/miniforge3/envs/research_env/lib/python3.10/site-packages/keras/engine/functional.py:998\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39mkeras_inputs):\n\u001b[1;32m    997\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(x) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m computable_tensors:\n\u001b[0;32m--> 998\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraph disconnected: cannot obtain value for tensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. The following previous layers \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwere accessed without issue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayers_with_complete_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39moutputs):\n\u001b[1;32m   1003\u001b[0m   computable_tensors\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(x))\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 3, 100, 100), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\") at layer \"conv_1\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "X = model.layers[-5].output\n",
    "x = Dense(4096, activation='relu', kernel_regularizer=l2(0.0001), name='dense_1')(X)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(4096, activation='relu', kernel_regularizer=l2(0.0001), name='dense_2')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(1000, activation='relu', kernel_regularizer=l2(0.0001), name='dense_3')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax', name='output')(x)\n",
    "\n",
    "TL_model = Model(inputs=model.input, outputs=outputs, name='Transfer Learning Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5272a88-b18d-40e9-bdc4-c9ca4059dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5),\n",
    "      ModelCheckpoint(filepath='best_weights.h5', monitor='val_acc', mode='max', \n",
    "        save_best_only=True)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7c0eb-f6bb-4be8-919d-2d8fe765d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "optimizer = 'adam'\n",
    "metrics = ['accuracy']\n",
    "# Multi-Class Cross-Entropy Loss\n",
    "loss = 'categorical_crossentropy' \n",
    "\n",
    "TL_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "TL_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21951565-33a3-4082-be6b-0bd8b36b4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train transfer learning model\n",
    "batch_size = 128\n",
    "NUM_EPOCH = 100\n",
    "\n",
    "history = TL_model.fit(X_train_1, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=NUM_EPOCH,\n",
    "                    validation_data=(X_valid_1, Y_valid),\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=es\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2033f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on noisy year 10 test data\n",
    "score = TL_model.evaluate(X_test_10, Y_test, verbose=True)\n",
    "print(\"%s: %.2f%%\" % (TL_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "score = TL_model.evaluate(X_test_10_sub, Y_test, verbose=True)\n",
    "print(\"%s: %.2f%%\" % (TL_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2adcb70-98ae-44bc-b0dd-dbb2ccd2c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TL_model.save_weights(\"TL_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1f804",
   "metadata": {},
   "source": [
    "# Probabilistic CNN model\n",
    "Define prior and the posterior distributions of weights\n",
    "\n",
    "Output a distribution instead of a deterministic tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "from tensorflow_probability.layers import OneHotCategorical\n",
    "print(\"Tensorflow Probability Version: \", tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative log-likelihood loss function\n",
    "def nll(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4d382-813d-41ea-9003-65cf0a537693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prior distribution\n",
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(len(outputs), dtype=tf.float64),\n",
    "                                   scale=1.0), reinterpreted_batch_ndims=1)\n",
    "\n",
    "# For Reparameterization Layers\n",
    "def posterior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    posterior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.VariableLayer(\n",
    "                tfp.layers.MultivariateNormalTriL.params_size(n), dtype=dtype\n",
    "            ),\n",
    "            tfp.layers.MultivariateNormalTriL(n),\n",
    "        ]\n",
    "    )\n",
    "    return posterior_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d87bbc0-882f-44ea-8d1b-9baf095270f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define probabalistic model architecture\n",
    "# change dense layers to DenseFlipout or DenseVariational to get\n",
    "# aleotoric and epistemic uncertainty\n",
    "input_shape = (3, 100, 100)\n",
    "\n",
    "# Constraints for block 1\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same', data_format='channels_first', name='conv_1')(inputs)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_1')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "# Constraints for block 2\n",
    "x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_3')(x)\n",
    "x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_4')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_2')(x)\n",
    "x = Dropout(rate=0.8)(x)\n",
    "\n",
    "# Constraints for block 3\n",
    "x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_5')(x)\n",
    "x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_6')(x)\n",
    "x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_7')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_3')(x)\n",
    "x = Dropout(rate=0.8)(x)\n",
    "\n",
    "# Constraints for block 4\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_8')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_9')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_10')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_4')(x)\n",
    "x = Dropout(rate=0.8)(x)\n",
    "\n",
    "# Constraints for block 5\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_11')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_12')(x)\n",
    "x = Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', data_format='channels_first', name='conv_13')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format='channels_first', name='maxpool_5')(x)\n",
    "x = Dropout(rate=0.8)(x)\n",
    "\n",
    "# flatten (or unroll) the 3D output to 1D\n",
    "x = Flatten()(x)\n",
    "\n",
    "# hidden layers\n",
    "x = Dense(tfpl.OneHotCategorical.params_size(3))(x)\n",
    "outputs = tfpl.OneHotCategorical(3, convert_to_tensor_fn=tfd.Distribution.mode)(x)\n",
    "\n",
    "probabilistic_model = Model(inputs=inputs, outputs=outputs, name='Probabilistic Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e600ec-3217-4053-b567-7aab77e7bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "probabilistic_model.compile( \n",
    "    optimizer='adam',\n",
    "    loss=nll,\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "probabilistic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78da0aa-1e79-424f-9285-058bf3dcae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the probabalistic model\n",
    "tf.random.set_seed(0)\n",
    "NUM_EPOCH = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67b36c-074c-4f28-8b5e-be943f61c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using one-hot version of the labels\n",
    "probabilistic_model.fit(X_train_1, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=NUM_EPOCH,              \n",
    "                    shuffle=True,\n",
    "                    verbose=True,\n",
    "                    callbacks=es\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b09b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "score = probabilistic_model.evaluate(X_test_1, Y_test, verbose=True)\n",
    "print(\"%s: %.2f%%\" % (probabilistic_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# Evaluate the model on test smaller subset\n",
    "score = probabilistic_model.evaluate(X_test_1_sub, Y_test_sub, verbose=True)\n",
    "print(\"%s: %.2f%%\" % (probabilistic_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a2d4f8-3745-401c-88da-d2f9aba8f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at probabilities of each class\n",
    "for i in [0,len(X_train)]:\n",
    "    image = X_test_1[i]\n",
    "    true_label = Y_test[i, 0]\n",
    "    predicted_probabilities = np.empty(shape=(len(X_train), 10))\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "    predicted_probabilities[i] = model(image[np.newaxis, :]).mean().numpy()[0]\n",
    "    model_prediction = probabilistic_model(image[np.newaxis, :])\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 2),\n",
    "                                   gridspec_kw={'width_ratios': [2, 4]})\n",
    "    \n",
    "    # Show the image and the true label\n",
    "    ax1.imshow(image[..., 0], cmap='gray')\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('True label: {}'.format(str(true_label)))\n",
    "    \n",
    "    # Show a 95% prediction interval of model predicted probabilities\n",
    "    # make plots of probabilities that the model estimates\n",
    "    pct_2p5 = np.array([np.percentile(predicted_probabilities[:, i], 2.5) for i in range(10)])\n",
    "    pct_97p5 = np.array([np.percentile(predicted_probabilities[:, i], 97.5) for i in range(10)])    \n",
    "    bar = ax2.bar(np.arange(10), pct_97p5, color='red')\n",
    "    bar[int(true_label)].set_color('green')\n",
    "    ax2.bar(np.arange(10), pct_2p5-0.02, color='white', linewidth=1, edgecolor='white')\n",
    "    ax2.set_xticks(np.arange(10))\n",
    "    ax2.set_ylim([0, 1])\n",
    "    ax2.set_ylabel('Probability')\n",
    "    ax2.set_title('Model estimated probabilities')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78f398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research_env)",
   "language": "python",
   "name": "research_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
